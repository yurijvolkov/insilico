{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:13:37.628407Z",
     "start_time": "2018-05-01T12:13:37.335110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '3590e9b0-7fa5-45de-bdf3-3f5f031cea9c' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '3590e9b0-7fa5-45de-bdf3-3f5f031cea9c' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"3590e9b0-7fa5-45de-bdf3-3f5f031cea9c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as mtcs\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.ensemble as ens\n",
    "import sklearn.feature_selection as fs\n",
    "import sklearn.neural_network as nn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model.base import BaseEstimator\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from xgboost import XGBClassifier\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "%matplotlib inline\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:30:36.674739Z",
     "start_time": "2018-05-01T11:30:36.438874Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL = 1524\n",
    "\n",
    "def weight_init(name, shape):\n",
    "    return tf.get_variable(name, initializer=tf.random_normal(shape=shape,\n",
    "                                                              stddev=0.1))\n",
    "def bias_init(name, shape):\n",
    "    return tf.get_variable(name, initializer=tf.constant(0.1, shape=shape))\n",
    "\n",
    "def elastic_net(x, l1, l2):\n",
    "    return l1 * ( (1-l2) / 2 * tf.norm(x, 2) ** 2 + \n",
    "                   l2 * tf.norm(x, 1))\n",
    "\n",
    "def batch_data(*matrxs, batch_size):\n",
    "    for batch_i in range(matrxs[0].shape[0] // batch_size):\n",
    "        yield tuple(x.iloc[batch_i * batch_size : (batch_i + 1) * batch_size] \n",
    "                     for x in matrxs)\n",
    "        \n",
    "def split_data3(data, train_size=0.5, test_size=0.25, validate_size=0.25):\n",
    "    train_data, test_val_data = ms.train_test_split(data, train_size=train_size)\n",
    "    test_data, val_data = ms.train_test_split(test_val_data,\n",
    "                                              train_size=test_size / (test_size+validate_size))\n",
    "    \n",
    "    train_X, train_y = train_data.drop('y', axis=1), train_data[['y']]\n",
    "    test_X, test_y = test_data.drop('y', axis=1), test_data[['y']]\n",
    "    validate_X, validate_y = val_data.drop('y', axis=1), val_data[['y']]\n",
    "    \n",
    "    return (train_X, train_y, test_X, test_y, validate_X, validate_y)\n",
    "\n",
    "def split_data2(data, train_size, test_size):\n",
    "    train_data, test_data = ms.train_test_split(data, train_size=train_size,\n",
    "                                                stratify=data.y)\n",
    "    train_X, train_y = train_data.drop('y', axis=1), train_data[['y']]\n",
    "    test_X, test_y = test_data.drop('y', axis=1), test_data[['y']]\n",
    "    \n",
    "    return (train_X, train_y, test_X, test_y)\n",
    "    \n",
    "\n",
    "def pp_pipeline(data):\n",
    "    scaler = pp.StandardScaler()\n",
    "    \n",
    "    data_pp = scaler.fit_transform(data)\n",
    "    \n",
    "    data_pp = pd.DataFrame(data_pp,\n",
    "                        index=data.index,\n",
    "                        columns=data.columns)\n",
    "    \n",
    "    #restore target\n",
    "    data_pp.y = data.y\n",
    "    \n",
    "    return data_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data uploading&preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:09:33.946012Z",
     "start_time": "2018-05-01T11:09:32.870541Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature-0</th>\n",
       "      <th>feature-1</th>\n",
       "      <th>feature-2</th>\n",
       "      <th>feature-3</th>\n",
       "      <th>feature-4</th>\n",
       "      <th>feature-5</th>\n",
       "      <th>feature-6</th>\n",
       "      <th>feature-7</th>\n",
       "      <th>feature-8</th>\n",
       "      <th>feature-9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature-1515</th>\n",
       "      <th>feature-1516</th>\n",
       "      <th>feature-1517</th>\n",
       "      <th>feature-1518</th>\n",
       "      <th>feature-1519</th>\n",
       "      <th>feature-1520</th>\n",
       "      <th>feature-1521</th>\n",
       "      <th>feature-1522</th>\n",
       "      <th>feature-1523</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.977273</td>\n",
       "      <td>6.758452</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>10.792929</td>\n",
       "      <td>160.801682</td>\n",
       "      <td>151.109783</td>\n",
       "      <td>1.791689</td>\n",
       "      <td>6.818675</td>\n",
       "      <td>8.138413</td>\n",
       "      <td>8.270161</td>\n",
       "      <td>...</td>\n",
       "      <td>5.658393</td>\n",
       "      <td>4.151040</td>\n",
       "      <td>4.540632</td>\n",
       "      <td>4.953183</td>\n",
       "      <td>5.351562</td>\n",
       "      <td>5.311048</td>\n",
       "      <td>5.560922</td>\n",
       "      <td>5.643015</td>\n",
       "      <td>5.715999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.408163</td>\n",
       "      <td>5.933978</td>\n",
       "      <td>2.816327</td>\n",
       "      <td>5.877551</td>\n",
       "      <td>162.949911</td>\n",
       "      <td>76.153796</td>\n",
       "      <td>1.381401</td>\n",
       "      <td>6.002651</td>\n",
       "      <td>5.080499</td>\n",
       "      <td>7.514421</td>\n",
       "      <td>...</td>\n",
       "      <td>4.830811</td>\n",
       "      <td>3.817712</td>\n",
       "      <td>4.123094</td>\n",
       "      <td>4.426343</td>\n",
       "      <td>4.823804</td>\n",
       "      <td>4.652173</td>\n",
       "      <td>4.795274</td>\n",
       "      <td>4.860781</td>\n",
       "      <td>5.001426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.265306</td>\n",
       "      <td>7.425645</td>\n",
       "      <td>3.734694</td>\n",
       "      <td>13.160998</td>\n",
       "      <td>172.099640</td>\n",
       "      <td>161.790879</td>\n",
       "      <td>1.603976</td>\n",
       "      <td>7.410120</td>\n",
       "      <td>10.114794</td>\n",
       "      <td>8.805738</td>\n",
       "      <td>...</td>\n",
       "      <td>6.397659</td>\n",
       "      <td>4.223177</td>\n",
       "      <td>4.685597</td>\n",
       "      <td>5.116870</td>\n",
       "      <td>5.333926</td>\n",
       "      <td>5.504569</td>\n",
       "      <td>5.797956</td>\n",
       "      <td>6.009581</td>\n",
       "      <td>6.200889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.976744</td>\n",
       "      <td>7.648293</td>\n",
       "      <td>3.837209</td>\n",
       "      <td>14.392765</td>\n",
       "      <td>168.885456</td>\n",
       "      <td>175.277251</td>\n",
       "      <td>1.622298</td>\n",
       "      <td>7.629033</td>\n",
       "      <td>12.180817</td>\n",
       "      <td>9.070719</td>\n",
       "      <td>...</td>\n",
       "      <td>5.879135</td>\n",
       "      <td>4.280132</td>\n",
       "      <td>4.563045</td>\n",
       "      <td>5.007714</td>\n",
       "      <td>5.159773</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>5.640132</td>\n",
       "      <td>5.472271</td>\n",
       "      <td>5.741399</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.320988</td>\n",
       "      <td>6.534011</td>\n",
       "      <td>3.567901</td>\n",
       "      <td>8.913580</td>\n",
       "      <td>163.076959</td>\n",
       "      <td>96.019681</td>\n",
       "      <td>1.380679</td>\n",
       "      <td>6.566695</td>\n",
       "      <td>4.417010</td>\n",
       "      <td>8.058783</td>\n",
       "      <td>...</td>\n",
       "      <td>8.148663</td>\n",
       "      <td>4.624973</td>\n",
       "      <td>5.173321</td>\n",
       "      <td>5.720312</td>\n",
       "      <td>6.259342</td>\n",
       "      <td>6.626469</td>\n",
       "      <td>7.062406</td>\n",
       "      <td>7.472998</td>\n",
       "      <td>7.829842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.924051</td>\n",
       "      <td>6.134299</td>\n",
       "      <td>3.037975</td>\n",
       "      <td>6.506329</td>\n",
       "      <td>165.707039</td>\n",
       "      <td>82.761541</td>\n",
       "      <td>1.381957</td>\n",
       "      <td>6.187547</td>\n",
       "      <td>4.684599</td>\n",
       "      <td>7.660347</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087556</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.820282</td>\n",
       "      <td>5.183187</td>\n",
       "      <td>5.595176</td>\n",
       "      <td>5.489454</td>\n",
       "      <td>5.604998</td>\n",
       "      <td>5.847522</td>\n",
       "      <td>5.987080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.150000</td>\n",
       "      <td>6.740695</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>10.214815</td>\n",
       "      <td>164.252922</td>\n",
       "      <td>135.639059</td>\n",
       "      <td>1.620887</td>\n",
       "      <td>6.781702</td>\n",
       "      <td>8.631090</td>\n",
       "      <td>8.248393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.198225</td>\n",
       "      <td>4.471639</td>\n",
       "      <td>4.801970</td>\n",
       "      <td>5.237107</td>\n",
       "      <td>5.493833</td>\n",
       "      <td>5.573816</td>\n",
       "      <td>5.764799</td>\n",
       "      <td>5.865760</td>\n",
       "      <td>5.998937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.833333</td>\n",
       "      <td>6.395508</td>\n",
       "      <td>3.141026</td>\n",
       "      <td>8.717949</td>\n",
       "      <td>163.221967</td>\n",
       "      <td>94.106131</td>\n",
       "      <td>1.435936</td>\n",
       "      <td>6.443753</td>\n",
       "      <td>5.834402</td>\n",
       "      <td>7.904135</td>\n",
       "      <td>...</td>\n",
       "      <td>6.582328</td>\n",
       "      <td>4.600158</td>\n",
       "      <td>5.032071</td>\n",
       "      <td>5.499726</td>\n",
       "      <td>5.978728</td>\n",
       "      <td>5.995208</td>\n",
       "      <td>6.179952</td>\n",
       "      <td>6.364051</td>\n",
       "      <td>6.481290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.380952</td>\n",
       "      <td>6.152543</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>6.402116</td>\n",
       "      <td>164.380868</td>\n",
       "      <td>128.391104</td>\n",
       "      <td>1.687697</td>\n",
       "      <td>6.232890</td>\n",
       "      <td>4.476844</td>\n",
       "      <td>7.736528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.449988</td>\n",
       "      <td>3.865979</td>\n",
       "      <td>4.506730</td>\n",
       "      <td>4.765906</td>\n",
       "      <td>4.965028</td>\n",
       "      <td>3.840795</td>\n",
       "      <td>3.595598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.228571</td>\n",
       "      <td>6.608449</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.180952</td>\n",
       "      <td>159.167580</td>\n",
       "      <td>180.141749</td>\n",
       "      <td>1.981354</td>\n",
       "      <td>6.690537</td>\n",
       "      <td>8.428546</td>\n",
       "      <td>8.221041</td>\n",
       "      <td>...</td>\n",
       "      <td>5.214936</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>4.890349</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>5.342334</td>\n",
       "      <td>5.402677</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.757143</td>\n",
       "      <td>6.241471</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>6.949206</td>\n",
       "      <td>167.005923</td>\n",
       "      <td>97.692813</td>\n",
       "      <td>1.408460</td>\n",
       "      <td>6.289021</td>\n",
       "      <td>5.919754</td>\n",
       "      <td>7.789862</td>\n",
       "      <td>...</td>\n",
       "      <td>6.175997</td>\n",
       "      <td>4.363099</td>\n",
       "      <td>4.716264</td>\n",
       "      <td>5.155457</td>\n",
       "      <td>5.591686</td>\n",
       "      <td>5.680173</td>\n",
       "      <td>5.977302</td>\n",
       "      <td>6.030986</td>\n",
       "      <td>6.214671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32.096774</td>\n",
       "      <td>7.206768</td>\n",
       "      <td>3.838710</td>\n",
       "      <td>13.806452</td>\n",
       "      <td>160.469926</td>\n",
       "      <td>127.646528</td>\n",
       "      <td>1.591140</td>\n",
       "      <td>7.228381</td>\n",
       "      <td>11.071685</td>\n",
       "      <td>8.598289</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242977</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>4.639572</td>\n",
       "      <td>5.151845</td>\n",
       "      <td>5.678037</td>\n",
       "      <td>5.850765</td>\n",
       "      <td>6.134888</td>\n",
       "      <td>6.451753</td>\n",
       "      <td>6.793466</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29.833333</td>\n",
       "      <td>6.436864</td>\n",
       "      <td>3.476190</td>\n",
       "      <td>8.296296</td>\n",
       "      <td>162.859109</td>\n",
       "      <td>118.257591</td>\n",
       "      <td>1.600911</td>\n",
       "      <td>6.497038</td>\n",
       "      <td>6.283812</td>\n",
       "      <td>7.960386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.658611</td>\n",
       "      <td>4.051785</td>\n",
       "      <td>4.519067</td>\n",
       "      <td>4.935373</td>\n",
       "      <td>5.281616</td>\n",
       "      <td>5.221369</td>\n",
       "      <td>5.465948</td>\n",
       "      <td>5.520210</td>\n",
       "      <td>5.499982</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.500000</td>\n",
       "      <td>6.700508</td>\n",
       "      <td>3.653846</td>\n",
       "      <td>10.709402</td>\n",
       "      <td>163.669041</td>\n",
       "      <td>145.244215</td>\n",
       "      <td>1.785651</td>\n",
       "      <td>6.764423</td>\n",
       "      <td>7.295706</td>\n",
       "      <td>8.158660</td>\n",
       "      <td>...</td>\n",
       "      <td>5.768126</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.356709</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>5.326662</td>\n",
       "      <td>5.340239</td>\n",
       "      <td>5.395331</td>\n",
       "      <td>5.454787</td>\n",
       "      <td>5.557552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38.851852</td>\n",
       "      <td>7.402900</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>12.979424</td>\n",
       "      <td>170.018323</td>\n",
       "      <td>154.527750</td>\n",
       "      <td>1.476580</td>\n",
       "      <td>7.381493</td>\n",
       "      <td>11.933931</td>\n",
       "      <td>8.867678</td>\n",
       "      <td>...</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>4.543295</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27.534483</td>\n",
       "      <td>6.269883</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.973180</td>\n",
       "      <td>161.381053</td>\n",
       "      <td>109.038626</td>\n",
       "      <td>1.618478</td>\n",
       "      <td>6.345124</td>\n",
       "      <td>4.994148</td>\n",
       "      <td>7.791228</td>\n",
       "      <td>...</td>\n",
       "      <td>8.934004</td>\n",
       "      <td>4.644391</td>\n",
       "      <td>5.241747</td>\n",
       "      <td>5.930586</td>\n",
       "      <td>6.610360</td>\n",
       "      <td>7.088878</td>\n",
       "      <td>7.641069</td>\n",
       "      <td>8.134765</td>\n",
       "      <td>8.607916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.837500</td>\n",
       "      <td>6.722804</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>172.043543</td>\n",
       "      <td>93.939718</td>\n",
       "      <td>1.156748</td>\n",
       "      <td>6.710586</td>\n",
       "      <td>6.512587</td>\n",
       "      <td>8.234018</td>\n",
       "      <td>...</td>\n",
       "      <td>5.638355</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>4.532599</td>\n",
       "      <td>4.804021</td>\n",
       "      <td>5.043425</td>\n",
       "      <td>5.181784</td>\n",
       "      <td>5.337538</td>\n",
       "      <td>5.497168</td>\n",
       "      <td>5.568345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55.263158</td>\n",
       "      <td>7.389305</td>\n",
       "      <td>3.684211</td>\n",
       "      <td>12.257310</td>\n",
       "      <td>170.139845</td>\n",
       "      <td>220.606751</td>\n",
       "      <td>1.969099</td>\n",
       "      <td>7.412105</td>\n",
       "      <td>10.847813</td>\n",
       "      <td>8.885381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.617652</td>\n",
       "      <td>3.868593</td>\n",
       "      <td>4.357510</td>\n",
       "      <td>4.523146</td>\n",
       "      <td>4.789573</td>\n",
       "      <td>4.523146</td>\n",
       "      <td>3.944006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43.057692</td>\n",
       "      <td>7.061350</td>\n",
       "      <td>3.942308</td>\n",
       "      <td>11.871795</td>\n",
       "      <td>163.441127</td>\n",
       "      <td>171.586122</td>\n",
       "      <td>1.834505</td>\n",
       "      <td>7.104088</td>\n",
       "      <td>9.456211</td>\n",
       "      <td>8.542274</td>\n",
       "      <td>...</td>\n",
       "      <td>6.706174</td>\n",
       "      <td>4.508108</td>\n",
       "      <td>4.898772</td>\n",
       "      <td>5.374989</td>\n",
       "      <td>5.679959</td>\n",
       "      <td>5.755742</td>\n",
       "      <td>6.060582</td>\n",
       "      <td>6.240763</td>\n",
       "      <td>6.434747</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.886792</td>\n",
       "      <td>7.052642</td>\n",
       "      <td>3.943396</td>\n",
       "      <td>12.100629</td>\n",
       "      <td>164.829574</td>\n",
       "      <td>170.922688</td>\n",
       "      <td>1.833416</td>\n",
       "      <td>7.095513</td>\n",
       "      <td>8.143800</td>\n",
       "      <td>8.514148</td>\n",
       "      <td>...</td>\n",
       "      <td>6.976085</td>\n",
       "      <td>4.572130</td>\n",
       "      <td>5.115746</td>\n",
       "      <td>5.566195</td>\n",
       "      <td>5.936711</td>\n",
       "      <td>6.080505</td>\n",
       "      <td>6.198796</td>\n",
       "      <td>6.333335</td>\n",
       "      <td>6.652742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.761905</td>\n",
       "      <td>6.858500</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9.640212</td>\n",
       "      <td>168.739205</td>\n",
       "      <td>141.875852</td>\n",
       "      <td>1.456355</td>\n",
       "      <td>6.864043</td>\n",
       "      <td>11.470610</td>\n",
       "      <td>8.439979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.528571</td>\n",
       "      <td>6.482779</td>\n",
       "      <td>2.942857</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>171.920444</td>\n",
       "      <td>84.572241</td>\n",
       "      <td>1.127633</td>\n",
       "      <td>6.481077</td>\n",
       "      <td>5.269841</td>\n",
       "      <td>8.031493</td>\n",
       "      <td>...</td>\n",
       "      <td>5.036953</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>4.672829</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>4.890349</td>\n",
       "      <td>4.969813</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.054795</td>\n",
       "      <td>6.395890</td>\n",
       "      <td>3.164384</td>\n",
       "      <td>8.301370</td>\n",
       "      <td>162.696886</td>\n",
       "      <td>90.885447</td>\n",
       "      <td>1.370996</td>\n",
       "      <td>6.435699</td>\n",
       "      <td>6.796613</td>\n",
       "      <td>7.942436</td>\n",
       "      <td>...</td>\n",
       "      <td>6.182085</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>4.912655</td>\n",
       "      <td>5.181784</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>5.652489</td>\n",
       "      <td>5.831882</td>\n",
       "      <td>6.040255</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19.160000</td>\n",
       "      <td>6.067396</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>167.413784</td>\n",
       "      <td>75.058797</td>\n",
       "      <td>1.241288</td>\n",
       "      <td>6.107552</td>\n",
       "      <td>6.423333</td>\n",
       "      <td>7.651508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.131868</td>\n",
       "      <td>5.762305</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.109890</td>\n",
       "      <td>165.080662</td>\n",
       "      <td>66.885356</td>\n",
       "      <td>1.294529</td>\n",
       "      <td>5.828765</td>\n",
       "      <td>2.738324</td>\n",
       "      <td>7.375662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.448889</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.624973</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>5.351858</td>\n",
       "      <td>5.590987</td>\n",
       "      <td>5.834811</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28.432432</td>\n",
       "      <td>6.603514</td>\n",
       "      <td>4.324324</td>\n",
       "      <td>11.027027</td>\n",
       "      <td>153.571767</td>\n",
       "      <td>112.900411</td>\n",
       "      <td>1.738632</td>\n",
       "      <td>6.683730</td>\n",
       "      <td>6.055743</td>\n",
       "      <td>8.059202</td>\n",
       "      <td>...</td>\n",
       "      <td>8.293510</td>\n",
       "      <td>4.363099</td>\n",
       "      <td>5.012301</td>\n",
       "      <td>5.675469</td>\n",
       "      <td>6.310259</td>\n",
       "      <td>6.686641</td>\n",
       "      <td>7.157565</td>\n",
       "      <td>7.635515</td>\n",
       "      <td>8.018008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.500000</td>\n",
       "      <td>6.207650</td>\n",
       "      <td>2.954545</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>164.257367</td>\n",
       "      <td>85.172313</td>\n",
       "      <td>1.392726</td>\n",
       "      <td>6.258106</td>\n",
       "      <td>5.808081</td>\n",
       "      <td>7.738226</td>\n",
       "      <td>...</td>\n",
       "      <td>7.443490</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>4.828314</td>\n",
       "      <td>5.422745</td>\n",
       "      <td>6.018593</td>\n",
       "      <td>6.373640</td>\n",
       "      <td>6.751321</td>\n",
       "      <td>7.048332</td>\n",
       "      <td>7.302612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.428571</td>\n",
       "      <td>6.252383</td>\n",
       "      <td>2.885714</td>\n",
       "      <td>7.384127</td>\n",
       "      <td>164.322747</td>\n",
       "      <td>112.473778</td>\n",
       "      <td>1.536709</td>\n",
       "      <td>6.312869</td>\n",
       "      <td>6.333953</td>\n",
       "      <td>7.825781</td>\n",
       "      <td>...</td>\n",
       "      <td>3.791267</td>\n",
       "      <td>3.772761</td>\n",
       "      <td>4.081766</td>\n",
       "      <td>4.514972</td>\n",
       "      <td>4.873765</td>\n",
       "      <td>4.997212</td>\n",
       "      <td>4.848606</td>\n",
       "      <td>4.455074</td>\n",
       "      <td>4.352694</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38.658537</td>\n",
       "      <td>6.752610</td>\n",
       "      <td>3.682927</td>\n",
       "      <td>10.753388</td>\n",
       "      <td>159.812730</td>\n",
       "      <td>153.837907</td>\n",
       "      <td>1.814410</td>\n",
       "      <td>6.815551</td>\n",
       "      <td>8.392444</td>\n",
       "      <td>8.278695</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800228</td>\n",
       "      <td>4.098503</td>\n",
       "      <td>4.492841</td>\n",
       "      <td>4.938513</td>\n",
       "      <td>5.120237</td>\n",
       "      <td>5.262042</td>\n",
       "      <td>5.561162</td>\n",
       "      <td>5.568821</td>\n",
       "      <td>5.681878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21.670588</td>\n",
       "      <td>6.292286</td>\n",
       "      <td>2.882353</td>\n",
       "      <td>6.776471</td>\n",
       "      <td>167.982829</td>\n",
       "      <td>85.273347</td>\n",
       "      <td>1.296235</td>\n",
       "      <td>6.326075</td>\n",
       "      <td>4.991830</td>\n",
       "      <td>7.822375</td>\n",
       "      <td>...</td>\n",
       "      <td>6.577992</td>\n",
       "      <td>4.385147</td>\n",
       "      <td>4.798885</td>\n",
       "      <td>5.216633</td>\n",
       "      <td>5.602695</td>\n",
       "      <td>5.857442</td>\n",
       "      <td>6.151851</td>\n",
       "      <td>6.484856</td>\n",
       "      <td>6.339973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>23.849057</td>\n",
       "      <td>6.443296</td>\n",
       "      <td>3.584906</td>\n",
       "      <td>8.490566</td>\n",
       "      <td>165.656310</td>\n",
       "      <td>94.855312</td>\n",
       "      <td>1.429258</td>\n",
       "      <td>6.483247</td>\n",
       "      <td>5.732180</td>\n",
       "      <td>7.917090</td>\n",
       "      <td>...</td>\n",
       "      <td>8.145414</td>\n",
       "      <td>4.375757</td>\n",
       "      <td>5.032071</td>\n",
       "      <td>5.702949</td>\n",
       "      <td>6.339698</td>\n",
       "      <td>6.834210</td>\n",
       "      <td>7.294229</td>\n",
       "      <td>7.631557</td>\n",
       "      <td>8.007074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>20.528302</td>\n",
       "      <td>6.044432</td>\n",
       "      <td>3.603774</td>\n",
       "      <td>6.075472</td>\n",
       "      <td>162.424590</td>\n",
       "      <td>80.699025</td>\n",
       "      <td>1.402911</td>\n",
       "      <td>6.109594</td>\n",
       "      <td>3.789570</td>\n",
       "      <td>7.610526</td>\n",
       "      <td>...</td>\n",
       "      <td>7.481855</td>\n",
       "      <td>4.151040</td>\n",
       "      <td>4.734003</td>\n",
       "      <td>5.287636</td>\n",
       "      <td>5.850225</td>\n",
       "      <td>6.211102</td>\n",
       "      <td>6.591717</td>\n",
       "      <td>6.991033</td>\n",
       "      <td>7.274674</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>20.440000</td>\n",
       "      <td>5.968498</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>6.080000</td>\n",
       "      <td>161.064334</td>\n",
       "      <td>80.380964</td>\n",
       "      <td>1.456437</td>\n",
       "      <td>6.045898</td>\n",
       "      <td>3.411944</td>\n",
       "      <td>7.531384</td>\n",
       "      <td>...</td>\n",
       "      <td>7.520150</td>\n",
       "      <td>4.166665</td>\n",
       "      <td>4.725173</td>\n",
       "      <td>5.302683</td>\n",
       "      <td>5.881406</td>\n",
       "      <td>6.250458</td>\n",
       "      <td>6.631384</td>\n",
       "      <td>7.030719</td>\n",
       "      <td>7.325005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>24.333333</td>\n",
       "      <td>5.957881</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>5.509259</td>\n",
       "      <td>164.383290</td>\n",
       "      <td>95.963738</td>\n",
       "      <td>1.496938</td>\n",
       "      <td>6.033144</td>\n",
       "      <td>3.958207</td>\n",
       "      <td>7.545887</td>\n",
       "      <td>...</td>\n",
       "      <td>7.057353</td>\n",
       "      <td>4.131159</td>\n",
       "      <td>4.601413</td>\n",
       "      <td>5.158696</td>\n",
       "      <td>5.690359</td>\n",
       "      <td>6.054403</td>\n",
       "      <td>6.455334</td>\n",
       "      <td>6.873095</td>\n",
       "      <td>6.939417</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>23.375000</td>\n",
       "      <td>6.322417</td>\n",
       "      <td>3.203125</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>162.588954</td>\n",
       "      <td>92.261393</td>\n",
       "      <td>1.451475</td>\n",
       "      <td>6.377366</td>\n",
       "      <td>5.672743</td>\n",
       "      <td>7.837564</td>\n",
       "      <td>...</td>\n",
       "      <td>6.824985</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.919981</td>\n",
       "      <td>5.421641</td>\n",
       "      <td>5.892335</td>\n",
       "      <td>6.042336</td>\n",
       "      <td>6.333613</td>\n",
       "      <td>6.572807</td>\n",
       "      <td>6.736893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>41.800000</td>\n",
       "      <td>9.073735</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>180.387654</td>\n",
       "      <td>166.508642</td>\n",
       "      <td>1.000430</td>\n",
       "      <td>8.896735</td>\n",
       "      <td>19.768056</td>\n",
       "      <td>10.349211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>18.390244</td>\n",
       "      <td>5.605241</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.731707</td>\n",
       "      <td>158.624476</td>\n",
       "      <td>72.159797</td>\n",
       "      <td>1.549658</td>\n",
       "      <td>5.717783</td>\n",
       "      <td>2.198509</td>\n",
       "      <td>7.184370</td>\n",
       "      <td>...</td>\n",
       "      <td>7.163209</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4.559126</td>\n",
       "      <td>5.140200</td>\n",
       "      <td>5.685703</td>\n",
       "      <td>5.885409</td>\n",
       "      <td>6.272759</td>\n",
       "      <td>6.609097</td>\n",
       "      <td>6.919128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>23.458333</td>\n",
       "      <td>6.397181</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>166.060607</td>\n",
       "      <td>93.350066</td>\n",
       "      <td>1.430009</td>\n",
       "      <td>6.439448</td>\n",
       "      <td>5.322917</td>\n",
       "      <td>7.869501</td>\n",
       "      <td>...</td>\n",
       "      <td>8.177485</td>\n",
       "      <td>4.297285</td>\n",
       "      <td>4.978456</td>\n",
       "      <td>5.658611</td>\n",
       "      <td>6.322790</td>\n",
       "      <td>6.818753</td>\n",
       "      <td>7.288522</td>\n",
       "      <td>7.655010</td>\n",
       "      <td>8.058613</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>25.809524</td>\n",
       "      <td>5.873886</td>\n",
       "      <td>3.380952</td>\n",
       "      <td>5.962963</td>\n",
       "      <td>162.051123</td>\n",
       "      <td>102.034265</td>\n",
       "      <td>1.656037</td>\n",
       "      <td>5.975364</td>\n",
       "      <td>2.317542</td>\n",
       "      <td>7.431153</td>\n",
       "      <td>...</td>\n",
       "      <td>7.555979</td>\n",
       "      <td>4.073291</td>\n",
       "      <td>4.650383</td>\n",
       "      <td>5.246695</td>\n",
       "      <td>5.735564</td>\n",
       "      <td>6.103816</td>\n",
       "      <td>6.545754</td>\n",
       "      <td>6.979000</td>\n",
       "      <td>7.346393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>21.414634</td>\n",
       "      <td>5.975237</td>\n",
       "      <td>3.487805</td>\n",
       "      <td>6.926829</td>\n",
       "      <td>161.339153</td>\n",
       "      <td>84.405257</td>\n",
       "      <td>1.534660</td>\n",
       "      <td>6.062522</td>\n",
       "      <td>3.468157</td>\n",
       "      <td>7.496018</td>\n",
       "      <td>...</td>\n",
       "      <td>7.446209</td>\n",
       "      <td>4.212128</td>\n",
       "      <td>4.888468</td>\n",
       "      <td>5.525951</td>\n",
       "      <td>5.975081</td>\n",
       "      <td>6.299380</td>\n",
       "      <td>6.681394</td>\n",
       "      <td>7.067183</td>\n",
       "      <td>7.171165</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.884906</td>\n",
       "      <td>2.759259</td>\n",
       "      <td>5.370370</td>\n",
       "      <td>162.831246</td>\n",
       "      <td>74.502082</td>\n",
       "      <td>1.381487</td>\n",
       "      <td>5.956572</td>\n",
       "      <td>3.660108</td>\n",
       "      <td>7.471168</td>\n",
       "      <td>...</td>\n",
       "      <td>5.514688</td>\n",
       "      <td>3.901973</td>\n",
       "      <td>4.327438</td>\n",
       "      <td>4.732904</td>\n",
       "      <td>5.096431</td>\n",
       "      <td>5.080239</td>\n",
       "      <td>5.365684</td>\n",
       "      <td>5.482980</td>\n",
       "      <td>5.400140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>23.318182</td>\n",
       "      <td>6.330339</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>8.045455</td>\n",
       "      <td>163.149857</td>\n",
       "      <td>92.872249</td>\n",
       "      <td>1.484800</td>\n",
       "      <td>6.384780</td>\n",
       "      <td>4.174874</td>\n",
       "      <td>7.815815</td>\n",
       "      <td>...</td>\n",
       "      <td>6.172744</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>4.569543</td>\n",
       "      <td>5.057837</td>\n",
       "      <td>5.539301</td>\n",
       "      <td>5.568821</td>\n",
       "      <td>5.728170</td>\n",
       "      <td>5.901779</td>\n",
       "      <td>5.917717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>20.560000</td>\n",
       "      <td>6.123796</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>165.088853</td>\n",
       "      <td>80.788719</td>\n",
       "      <td>1.335059</td>\n",
       "      <td>6.174052</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>7.684390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.238678</td>\n",
       "      <td>3.669951</td>\n",
       "      <td>4.112921</td>\n",
       "      <td>4.525180</td>\n",
       "      <td>4.251170</td>\n",
       "      <td>4.104707</td>\n",
       "      <td>3.446011</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>22.380952</td>\n",
       "      <td>6.182614</td>\n",
       "      <td>3.349206</td>\n",
       "      <td>7.396825</td>\n",
       "      <td>164.113227</td>\n",
       "      <td>89.449143</td>\n",
       "      <td>1.521852</td>\n",
       "      <td>6.248717</td>\n",
       "      <td>4.873016</td>\n",
       "      <td>7.649627</td>\n",
       "      <td>...</td>\n",
       "      <td>7.231355</td>\n",
       "      <td>4.545951</td>\n",
       "      <td>5.133590</td>\n",
       "      <td>5.739994</td>\n",
       "      <td>6.264469</td>\n",
       "      <td>6.422816</td>\n",
       "      <td>6.771282</td>\n",
       "      <td>7.089077</td>\n",
       "      <td>7.031227</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>25.161290</td>\n",
       "      <td>5.774461</td>\n",
       "      <td>2.806452</td>\n",
       "      <td>4.143369</td>\n",
       "      <td>166.212698</td>\n",
       "      <td>99.236969</td>\n",
       "      <td>1.531852</td>\n",
       "      <td>5.860845</td>\n",
       "      <td>2.388103</td>\n",
       "      <td>7.386058</td>\n",
       "      <td>...</td>\n",
       "      <td>3.954843</td>\n",
       "      <td>3.409496</td>\n",
       "      <td>3.868593</td>\n",
       "      <td>4.382808</td>\n",
       "      <td>4.539297</td>\n",
       "      <td>4.549261</td>\n",
       "      <td>4.743845</td>\n",
       "      <td>4.850075</td>\n",
       "      <td>4.323304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>18.074074</td>\n",
       "      <td>5.806478</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>4.518519</td>\n",
       "      <td>164.385174</td>\n",
       "      <td>70.742453</td>\n",
       "      <td>1.348570</td>\n",
       "      <td>5.877785</td>\n",
       "      <td>3.391975</td>\n",
       "      <td>7.397610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.198673</td>\n",
       "      <td>3.630985</td>\n",
       "      <td>4.009603</td>\n",
       "      <td>4.409003</td>\n",
       "      <td>3.997053</td>\n",
       "      <td>4.066888</td>\n",
       "      <td>3.725693</td>\n",
       "      <td>2.784239</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>21.284553</td>\n",
       "      <td>6.179102</td>\n",
       "      <td>3.219512</td>\n",
       "      <td>6.975610</td>\n",
       "      <td>164.084221</td>\n",
       "      <td>83.736404</td>\n",
       "      <td>1.363989</td>\n",
       "      <td>6.230333</td>\n",
       "      <td>4.664747</td>\n",
       "      <td>7.732390</td>\n",
       "      <td>...</td>\n",
       "      <td>8.626406</td>\n",
       "      <td>4.923624</td>\n",
       "      <td>5.447814</td>\n",
       "      <td>5.972218</td>\n",
       "      <td>6.539676</td>\n",
       "      <td>7.003520</td>\n",
       "      <td>7.460310</td>\n",
       "      <td>7.890512</td>\n",
       "      <td>8.276919</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>19.658537</td>\n",
       "      <td>5.914988</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>5.756098</td>\n",
       "      <td>166.863082</td>\n",
       "      <td>77.226327</td>\n",
       "      <td>1.395619</td>\n",
       "      <td>5.985012</td>\n",
       "      <td>2.447832</td>\n",
       "      <td>7.443992</td>\n",
       "      <td>...</td>\n",
       "      <td>6.598232</td>\n",
       "      <td>3.886705</td>\n",
       "      <td>4.389809</td>\n",
       "      <td>4.926801</td>\n",
       "      <td>5.261718</td>\n",
       "      <td>5.494090</td>\n",
       "      <td>5.865848</td>\n",
       "      <td>6.204873</td>\n",
       "      <td>6.369954</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>17.720930</td>\n",
       "      <td>5.750228</td>\n",
       "      <td>2.697674</td>\n",
       "      <td>4.604651</td>\n",
       "      <td>164.527087</td>\n",
       "      <td>69.324920</td>\n",
       "      <td>1.357124</td>\n",
       "      <td>5.825972</td>\n",
       "      <td>3.025840</td>\n",
       "      <td>7.340613</td>\n",
       "      <td>...</td>\n",
       "      <td>5.196423</td>\n",
       "      <td>3.676301</td>\n",
       "      <td>4.123094</td>\n",
       "      <td>4.647990</td>\n",
       "      <td>5.085665</td>\n",
       "      <td>5.169063</td>\n",
       "      <td>5.358942</td>\n",
       "      <td>5.594479</td>\n",
       "      <td>5.380329</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>17.225806</td>\n",
       "      <td>5.579190</td>\n",
       "      <td>2.548387</td>\n",
       "      <td>4.193548</td>\n",
       "      <td>161.392477</td>\n",
       "      <td>67.383958</td>\n",
       "      <td>1.452391</td>\n",
       "      <td>5.679165</td>\n",
       "      <td>2.590502</td>\n",
       "      <td>7.175556</td>\n",
       "      <td>...</td>\n",
       "      <td>3.840795</td>\n",
       "      <td>3.349904</td>\n",
       "      <td>3.682610</td>\n",
       "      <td>4.071161</td>\n",
       "      <td>4.447785</td>\n",
       "      <td>4.003918</td>\n",
       "      <td>4.150055</td>\n",
       "      <td>4.274928</td>\n",
       "      <td>4.123094</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>25.841270</td>\n",
       "      <td>6.257190</td>\n",
       "      <td>3.301587</td>\n",
       "      <td>7.499118</td>\n",
       "      <td>165.929853</td>\n",
       "      <td>102.114039</td>\n",
       "      <td>1.475191</td>\n",
       "      <td>6.312625</td>\n",
       "      <td>4.628210</td>\n",
       "      <td>7.790568</td>\n",
       "      <td>...</td>\n",
       "      <td>8.508140</td>\n",
       "      <td>4.551242</td>\n",
       "      <td>5.176856</td>\n",
       "      <td>5.812076</td>\n",
       "      <td>6.371825</td>\n",
       "      <td>6.850507</td>\n",
       "      <td>7.327036</td>\n",
       "      <td>7.760788</td>\n",
       "      <td>8.122028</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>19.416667</td>\n",
       "      <td>6.040173</td>\n",
       "      <td>2.826389</td>\n",
       "      <td>5.763889</td>\n",
       "      <td>164.563288</td>\n",
       "      <td>76.121662</td>\n",
       "      <td>1.298125</td>\n",
       "      <td>6.090735</td>\n",
       "      <td>4.419416</td>\n",
       "      <td>7.632631</td>\n",
       "      <td>...</td>\n",
       "      <td>6.257668</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>5.105945</td>\n",
       "      <td>5.313206</td>\n",
       "      <td>5.537334</td>\n",
       "      <td>5.620401</td>\n",
       "      <td>5.805135</td>\n",
       "      <td>5.976351</td>\n",
       "      <td>6.091310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>22.877193</td>\n",
       "      <td>5.824621</td>\n",
       "      <td>2.912281</td>\n",
       "      <td>5.130604</td>\n",
       "      <td>162.065226</td>\n",
       "      <td>90.113408</td>\n",
       "      <td>1.522993</td>\n",
       "      <td>5.913365</td>\n",
       "      <td>2.939753</td>\n",
       "      <td>7.426243</td>\n",
       "      <td>...</td>\n",
       "      <td>5.575239</td>\n",
       "      <td>4.056123</td>\n",
       "      <td>4.501198</td>\n",
       "      <td>4.960657</td>\n",
       "      <td>5.184939</td>\n",
       "      <td>5.169418</td>\n",
       "      <td>5.403803</td>\n",
       "      <td>5.604422</td>\n",
       "      <td>5.480118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>18.912281</td>\n",
       "      <td>5.693595</td>\n",
       "      <td>2.929825</td>\n",
       "      <td>5.228070</td>\n",
       "      <td>158.876430</td>\n",
       "      <td>74.254334</td>\n",
       "      <td>1.530849</td>\n",
       "      <td>5.798249</td>\n",
       "      <td>2.397661</td>\n",
       "      <td>7.270916</td>\n",
       "      <td>...</td>\n",
       "      <td>7.533869</td>\n",
       "      <td>4.255613</td>\n",
       "      <td>4.826312</td>\n",
       "      <td>5.403240</td>\n",
       "      <td>5.979993</td>\n",
       "      <td>6.177425</td>\n",
       "      <td>6.654314</td>\n",
       "      <td>7.047680</td>\n",
       "      <td>7.348266</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>25.464286</td>\n",
       "      <td>6.616246</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>163.099820</td>\n",
       "      <td>100.684505</td>\n",
       "      <td>1.421288</td>\n",
       "      <td>6.649411</td>\n",
       "      <td>7.740823</td>\n",
       "      <td>8.113419</td>\n",
       "      <td>...</td>\n",
       "      <td>7.724212</td>\n",
       "      <td>4.424847</td>\n",
       "      <td>5.028803</td>\n",
       "      <td>5.577369</td>\n",
       "      <td>6.031136</td>\n",
       "      <td>6.363244</td>\n",
       "      <td>6.711588</td>\n",
       "      <td>7.060610</td>\n",
       "      <td>7.424184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>19.133333</td>\n",
       "      <td>5.909660</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>165.378392</td>\n",
       "      <td>75.050748</td>\n",
       "      <td>1.361830</td>\n",
       "      <td>5.976143</td>\n",
       "      <td>4.137963</td>\n",
       "      <td>7.473203</td>\n",
       "      <td>...</td>\n",
       "      <td>3.446011</td>\n",
       "      <td>3.481240</td>\n",
       "      <td>3.907010</td>\n",
       "      <td>4.281861</td>\n",
       "      <td>4.720172</td>\n",
       "      <td>4.574711</td>\n",
       "      <td>4.320816</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>4.342993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>19.211268</td>\n",
       "      <td>5.922814</td>\n",
       "      <td>2.788732</td>\n",
       "      <td>5.802817</td>\n",
       "      <td>163.585967</td>\n",
       "      <td>75.352194</td>\n",
       "      <td>1.368851</td>\n",
       "      <td>5.990213</td>\n",
       "      <td>3.049394</td>\n",
       "      <td>7.502897</td>\n",
       "      <td>...</td>\n",
       "      <td>5.234112</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>4.791650</td>\n",
       "      <td>5.245707</td>\n",
       "      <td>5.667723</td>\n",
       "      <td>5.793776</td>\n",
       "      <td>5.960844</td>\n",
       "      <td>5.839187</td>\n",
       "      <td>5.411088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>27.312500</td>\n",
       "      <td>6.923266</td>\n",
       "      <td>3.406250</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>170.933703</td>\n",
       "      <td>108.146947</td>\n",
       "      <td>1.321618</td>\n",
       "      <td>6.921481</td>\n",
       "      <td>8.122396</td>\n",
       "      <td>8.348757</td>\n",
       "      <td>...</td>\n",
       "      <td>6.003578</td>\n",
       "      <td>3.921973</td>\n",
       "      <td>4.409763</td>\n",
       "      <td>4.898772</td>\n",
       "      <td>5.348595</td>\n",
       "      <td>5.559479</td>\n",
       "      <td>5.495630</td>\n",
       "      <td>5.703366</td>\n",
       "      <td>5.926259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>31.785714</td>\n",
       "      <td>6.290479</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>7.658730</td>\n",
       "      <td>161.230794</td>\n",
       "      <td>126.116779</td>\n",
       "      <td>1.718917</td>\n",
       "      <td>6.371939</td>\n",
       "      <td>5.511035</td>\n",
       "      <td>7.836350</td>\n",
       "      <td>...</td>\n",
       "      <td>5.931955</td>\n",
       "      <td>3.789855</td>\n",
       "      <td>4.367864</td>\n",
       "      <td>4.954506</td>\n",
       "      <td>5.430442</td>\n",
       "      <td>5.715330</td>\n",
       "      <td>6.065365</td>\n",
       "      <td>6.387320</td>\n",
       "      <td>5.916728</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>20.761905</td>\n",
       "      <td>6.057493</td>\n",
       "      <td>3.119048</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>164.681027</td>\n",
       "      <td>81.668748</td>\n",
       "      <td>1.401802</td>\n",
       "      <td>6.120762</td>\n",
       "      <td>3.509921</td>\n",
       "      <td>7.596294</td>\n",
       "      <td>...</td>\n",
       "      <td>6.846092</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>4.517704</td>\n",
       "      <td>5.125079</td>\n",
       "      <td>5.599347</td>\n",
       "      <td>5.933364</td>\n",
       "      <td>6.335871</td>\n",
       "      <td>6.708575</td>\n",
       "      <td>6.648544</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1105 rows  1525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature-0  feature-1  feature-2  feature-3   feature-4   feature-5  \\\n",
       "0     37.977273   6.758452   3.636364  10.792929  160.801682  151.109783   \n",
       "1     19.408163   5.933978   2.816327   5.877551  162.949911   76.153796   \n",
       "2     40.265306   7.425645   3.734694  13.160998  172.099640  161.790879   \n",
       "3     43.976744   7.648293   3.837209  14.392765  168.885456  175.277251   \n",
       "4     24.320988   6.534011   3.567901   8.913580  163.076959   96.019681   \n",
       "5     20.924051   6.134299   3.037975   6.506329  165.707039   82.761541   \n",
       "6     34.150000   6.740695   3.733333  10.214815  164.252922  135.639059   \n",
       "7     23.833333   6.395508   3.141026   8.717949  163.221967   94.106131   \n",
       "8     32.380952   6.152543   2.857143   6.402116  164.380868  128.391104   \n",
       "9     45.228571   6.608449   3.714286   9.180952  159.167580  180.141749   \n",
       "10    24.757143   6.241471   3.071429   6.949206  167.005923   97.692813   \n",
       "11    32.096774   7.206768   3.838710  13.806452  160.469926  127.646528   \n",
       "12    29.833333   6.436864   3.476190   8.296296  162.859109  118.257591   \n",
       "13    36.500000   6.700508   3.653846  10.709402  163.669041  145.244215   \n",
       "14    38.851852   7.402900   3.777778  12.979424  170.018323  154.527750   \n",
       "15    27.534483   6.269883   3.500000   7.973180  161.381053  109.038626   \n",
       "16    23.837500   6.722804   3.125000   7.875000  172.043543   93.939718   \n",
       "17    55.263158   7.389305   3.684211  12.257310  170.139845  220.606751   \n",
       "18    43.057692   7.061350   3.942308  11.871795  163.441127  171.586122   \n",
       "19    42.886792   7.052642   3.943396  12.100629  164.829574  170.922688   \n",
       "20    35.761905   6.858500   2.666667   9.640212  168.739205  141.875852   \n",
       "21    21.528571   6.482779   2.942857   6.400000  171.920444   84.572241   \n",
       "22    23.054795   6.395890   3.164384   8.301370  162.696886   90.885447   \n",
       "23    19.160000   6.067396   2.560000   5.920000  167.413784   75.058797   \n",
       "24    17.131868   5.762305   3.000000   4.109890  165.080662   66.885356   \n",
       "25    28.432432   6.603514   4.324324  11.027027  153.571767  112.900411   \n",
       "26    21.500000   6.207650   2.954545   7.272727  164.257367   85.172313   \n",
       "27    28.428571   6.252383   2.885714   7.384127  164.322747  112.473778   \n",
       "28    38.658537   6.752610   3.682927  10.753388  159.812730  153.837907   \n",
       "29    21.670588   6.292286   2.882353   6.776471  167.982829   85.273347   \n",
       "...         ...        ...        ...        ...         ...         ...   \n",
       "1075  23.849057   6.443296   3.584906   8.490566  165.656310   94.855312   \n",
       "1076  20.528302   6.044432   3.603774   6.075472  162.424590   80.699025   \n",
       "1077  20.440000   5.968498   3.700000   6.080000  161.064334   80.380964   \n",
       "1078  24.333333   5.957881   3.062500   5.509259  164.383290   95.963738   \n",
       "1079  23.375000   6.322417   3.203125   8.375000  162.588954   92.261393   \n",
       "1080  41.800000   9.073735   3.350000  21.400000  180.387654  166.508642   \n",
       "1081  18.390244   5.605241   3.000000   4.731707  158.624476   72.159797   \n",
       "1082  23.458333   6.397181   3.500000   8.375000  166.060607   93.350066   \n",
       "1083  25.809524   5.873886   3.380952   5.962963  162.051123  102.034265   \n",
       "1084  21.414634   5.975237   3.487805   6.926829  161.339153   84.405257   \n",
       "1085  19.000000   5.884906   2.759259   5.370370  162.831246   74.502082   \n",
       "1086  23.318182   6.330339   3.363636   8.045455  163.149857   92.872249   \n",
       "1087  20.560000   6.123796   2.680000   5.920000  165.088853   80.788719   \n",
       "1088  22.380952   6.182614   3.349206   7.396825  164.113227   89.449143   \n",
       "1089  25.161290   5.774461   2.806452   4.143369  166.212698   99.236969   \n",
       "1090  18.074074   5.806478   2.555556   4.518519  164.385174   70.742453   \n",
       "1091  21.284553   6.179102   3.219512   6.975610  164.084221   83.736404   \n",
       "1092  19.658537   5.914988   3.048780   5.756098  166.863082   77.226327   \n",
       "1093  17.720930   5.750228   2.697674   4.604651  164.527087   69.324920   \n",
       "1094  17.225806   5.579190   2.548387   4.193548  161.392477   67.383958   \n",
       "1095  25.841270   6.257190   3.301587   7.499118  165.929853  102.114039   \n",
       "1096  19.416667   6.040173   2.826389   5.763889  164.563288   76.121662   \n",
       "1097  22.877193   5.824621   2.912281   5.130604  162.065226   90.113408   \n",
       "1098  18.912281   5.693595   2.929825   5.228070  158.876430   74.254334   \n",
       "1099  25.464286   6.616246   3.750000   9.285714  163.099820  100.684505   \n",
       "1100  19.133333   5.909660   2.733333   5.466667  165.378392   75.050748   \n",
       "1101  19.211268   5.922814   2.788732   5.802817  163.585967   75.352194   \n",
       "1102  27.312500   6.923266   3.406250  10.750000  170.933703  108.146947   \n",
       "1103  31.785714   6.290479   3.357143   7.658730  161.230794  126.116779   \n",
       "1104  20.761905   6.057493   3.119048   6.476190  164.681027   81.668748   \n",
       "\n",
       "      feature-6  feature-7  feature-8  feature-9 ...   feature-1515  \\\n",
       "0      1.791689   6.818675   8.138413   8.270161 ...       5.658393   \n",
       "1      1.381401   6.002651   5.080499   7.514421 ...       4.830811   \n",
       "2      1.603976   7.410120  10.114794   8.805738 ...       6.397659   \n",
       "3      1.622298   7.629033  12.180817   9.070719 ...       5.879135   \n",
       "4      1.380679   6.566695   4.417010   8.058783 ...       8.148663   \n",
       "5      1.381957   6.187547   4.684599   7.660347 ...       6.087556   \n",
       "6      1.620887   6.781702   8.631090   8.248393 ...       6.198225   \n",
       "7      1.435936   6.443753   5.834402   7.904135 ...       6.582328   \n",
       "8      1.687697   6.232890   4.476844   7.736528 ...       0.000000   \n",
       "9      1.981354   6.690537   8.428546   8.221041 ...       5.214936   \n",
       "10     1.408460   6.289021   5.919754   7.789862 ...       6.175997   \n",
       "11     1.591140   7.228381  11.071685   8.598289 ...       7.242977   \n",
       "12     1.600911   6.497038   6.283812   7.960386 ...       5.658611   \n",
       "13     1.785651   6.764423   7.295706   8.158660 ...       5.768126   \n",
       "14     1.476580   7.381493  11.933931   8.867678 ...       3.218876   \n",
       "15     1.618478   6.345124   4.994148   7.791228 ...       8.934004   \n",
       "16     1.156748   6.710586   6.512587   8.234018 ...       5.638355   \n",
       "17     1.969099   7.412105  10.847813   8.885381 ...       0.000000   \n",
       "18     1.834505   7.104088   9.456211   8.542274 ...       6.706174   \n",
       "19     1.833416   7.095513   8.143800   8.514148 ...       6.976085   \n",
       "20     1.456355   6.864043  11.470610   8.439979 ...       0.000000   \n",
       "21     1.127633   6.481077   5.269841   8.031493 ...       5.036953   \n",
       "22     1.370996   6.435699   6.796613   7.942436 ...       6.182085   \n",
       "23     1.241288   6.107552   6.423333   7.651508 ...       0.000000   \n",
       "24     1.294529   5.828765   2.738324   7.375662 ...       6.448889   \n",
       "25     1.738632   6.683730   6.055743   8.059202 ...       8.293510   \n",
       "26     1.392726   6.258106   5.808081   7.738226 ...       7.443490   \n",
       "27     1.536709   6.312869   6.333953   7.825781 ...       3.791267   \n",
       "28     1.814410   6.815551   8.392444   8.278695 ...       5.800228   \n",
       "29     1.296235   6.326075   4.991830   7.822375 ...       6.577992   \n",
       "...         ...        ...        ...        ... ...            ...   \n",
       "1075   1.429258   6.483247   5.732180   7.917090 ...       8.145414   \n",
       "1076   1.402911   6.109594   3.789570   7.610526 ...       7.481855   \n",
       "1077   1.456437   6.045898   3.411944   7.531384 ...       7.520150   \n",
       "1078   1.496938   6.033144   3.958207   7.545887 ...       7.057353   \n",
       "1079   1.451475   6.377366   5.672743   7.837564 ...       6.824985   \n",
       "1080   1.000430   8.896735  19.768056  10.349211 ...       0.000000   \n",
       "1081   1.549658   5.717783   2.198509   7.184370 ...       7.163209   \n",
       "1082   1.430009   6.439448   5.322917   7.869501 ...       8.177485   \n",
       "1083   1.656037   5.975364   2.317542   7.431153 ...       7.555979   \n",
       "1084   1.534660   6.062522   3.468157   7.496018 ...       7.446209   \n",
       "1085   1.381487   5.956572   3.660108   7.471168 ...       5.514688   \n",
       "1086   1.484800   6.384780   4.174874   7.815815 ...       6.172744   \n",
       "1087   1.335059   6.174052   4.833333   7.684390 ...       0.000000   \n",
       "1088   1.521852   6.248717   4.873016   7.649627 ...       7.231355   \n",
       "1089   1.531852   5.860845   2.388103   7.386058 ...       3.954843   \n",
       "1090   1.348570   5.877785   3.391975   7.397610 ...       0.000000   \n",
       "1091   1.363989   6.230333   4.664747   7.732390 ...       8.626406   \n",
       "1092   1.395619   5.985012   2.447832   7.443992 ...       6.598232   \n",
       "1093   1.357124   5.825972   3.025840   7.340613 ...       5.196423   \n",
       "1094   1.452391   5.679165   2.590502   7.175556 ...       3.840795   \n",
       "1095   1.475191   6.312625   4.628210   7.790568 ...       8.508140   \n",
       "1096   1.298125   6.090735   4.419416   7.632631 ...       6.257668   \n",
       "1097   1.522993   5.913365   2.939753   7.426243 ...       5.575239   \n",
       "1098   1.530849   5.798249   2.397661   7.270916 ...       7.533869   \n",
       "1099   1.421288   6.649411   7.740823   8.113419 ...       7.724212   \n",
       "1100   1.361830   5.976143   4.137963   7.473203 ...       3.446011   \n",
       "1101   1.368851   5.990213   3.049394   7.502897 ...       5.234112   \n",
       "1102   1.321618   6.921481   8.122396   8.348757 ...       6.003578   \n",
       "1103   1.718917   6.371939   5.511035   7.836350 ...       5.931955   \n",
       "1104   1.401802   6.120762   3.509921   7.596294 ...       6.846092   \n",
       "\n",
       "      feature-1516  feature-1517  feature-1518  feature-1519  feature-1520  \\\n",
       "0         4.151040      4.540632      4.953183      5.351562      5.311048   \n",
       "1         3.817712      4.123094      4.426343      4.823804      4.652173   \n",
       "2         4.223177      4.685597      5.116870      5.333926      5.504569   \n",
       "3         4.280132      4.563045      5.007714      5.159773      5.393628   \n",
       "4         4.624973      5.173321      5.720312      6.259342      6.626469   \n",
       "5         4.430817      4.820282      5.183187      5.595176      5.489454   \n",
       "6         4.471639      4.801970      5.237107      5.493833      5.573816   \n",
       "7         4.600158      5.032071      5.499726      5.978728      5.995208   \n",
       "8         3.449988      3.865979      4.506730      4.765906      4.965028   \n",
       "9         3.828641      4.234107      4.682131      4.890349      5.192957   \n",
       "10        4.363099      4.716264      5.155457      5.591686      5.680173   \n",
       "11        4.094345      4.639572      5.151845      5.678037      5.850765   \n",
       "12        4.051785      4.519067      4.935373      5.281616      5.221369   \n",
       "13        3.931826      4.356709      4.844187      5.326662      5.340239   \n",
       "14        3.688879      3.761200      4.110874      4.442651      4.406719   \n",
       "15        4.644391      5.241747      5.930586      6.610360      7.088878   \n",
       "16        4.234107      4.532599      4.804021      5.043425      5.181784   \n",
       "17        3.617652      3.868593      4.357510      4.523146      4.789573   \n",
       "18        4.508108      4.898772      5.374989      5.679959      5.755742   \n",
       "19        4.572130      5.115746      5.566195      5.936711      6.080505   \n",
       "20        3.135494      2.484907      2.397895      2.302585      2.197225   \n",
       "21        3.931826      4.234107      4.442651      4.672829      4.753590   \n",
       "22        4.330733      4.605170      4.912655      5.181784      5.393628   \n",
       "23        2.833213      2.944439      2.944439      3.044522      3.044522   \n",
       "24        4.262680      4.624973      5.010635      5.351858      5.590987   \n",
       "25        4.363099      5.012301      5.675469      6.310259      6.686641   \n",
       "26        4.304065      4.828314      5.422745      6.018593      6.373640   \n",
       "27        3.772761      4.081766      4.514972      4.873765      4.997212   \n",
       "28        4.098503      4.492841      4.938513      5.120237      5.262042   \n",
       "29        4.385147      4.798885      5.216633      5.602695      5.857442   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1075      4.375757      5.032071      5.702949      6.339698      6.834210   \n",
       "1076      4.151040      4.734003      5.287636      5.850225      6.211102   \n",
       "1077      4.166665      4.725173      5.302683      5.881406      6.250458   \n",
       "1078      4.131159      4.601413      5.158696      5.690359      6.054403   \n",
       "1079      4.430817      4.919981      5.421641      5.892335      6.042336   \n",
       "1080      3.178054      2.890372      2.995732      3.135494      2.995732   \n",
       "1081      3.951244      4.559126      5.140200      5.685703      5.885409   \n",
       "1082      4.297285      4.978456      5.658611      6.322790      6.818753   \n",
       "1083      4.073291      4.650383      5.246695      5.735564      6.103816   \n",
       "1084      4.212128      4.888468      5.525951      5.975081      6.299380   \n",
       "1085      3.901973      4.327438      4.732904      5.096431      5.080239   \n",
       "1086      4.060443      4.569543      5.057837      5.539301      5.568821   \n",
       "1087      3.238678      3.669951      4.112921      4.525180      4.251170   \n",
       "1088      4.545951      5.133590      5.739994      6.264469      6.422816   \n",
       "1089      3.409496      3.868593      4.382808      4.539297      4.549261   \n",
       "1090      3.198673      3.630985      4.009603      4.409003      3.997053   \n",
       "1091      4.923624      5.447814      5.972218      6.539676      7.003520   \n",
       "1092      3.886705      4.389809      4.926801      5.261718      5.494090   \n",
       "1093      3.676301      4.123094      4.647990      5.085665      5.169063   \n",
       "1094      3.349904      3.682610      4.071161      4.447785      4.003918   \n",
       "1095      4.551242      5.176856      5.812076      6.371825      6.850507   \n",
       "1096      4.762174      5.105945      5.313206      5.537334      5.620401   \n",
       "1097      4.056123      4.501198      4.960657      5.184939      5.169418   \n",
       "1098      4.255613      4.826312      5.403240      5.979993      6.177425   \n",
       "1099      4.424847      5.028803      5.577369      6.031136      6.363244   \n",
       "1100      3.481240      3.907010      4.281861      4.720172      4.574711   \n",
       "1101      4.248495      4.791650      5.245707      5.667723      5.793776   \n",
       "1102      3.921973      4.409763      4.898772      5.348595      5.559479   \n",
       "1103      3.789855      4.367864      4.954506      5.430442      5.715330   \n",
       "1104      3.974998      4.517704      5.125079      5.599347      5.933364   \n",
       "\n",
       "      feature-1521  feature-1522  feature-1523    y  \n",
       "0         5.560922      5.643015      5.715999  0.0  \n",
       "1         4.795274      4.860781      5.001426  0.0  \n",
       "2         5.797956      6.009581      6.200889  0.0  \n",
       "3         5.640132      5.472271      5.741399  0.0  \n",
       "4         7.062406      7.472998      7.829842  0.0  \n",
       "5         5.604998      5.847522      5.987080  0.0  \n",
       "6         5.764799      5.865760      5.998937  0.0  \n",
       "7         6.179952      6.364051      6.481290  0.0  \n",
       "8         3.840795      3.595598      0.000000  0.0  \n",
       "9         5.342334      5.402677      5.303305  0.0  \n",
       "10        5.977302      6.030986      6.214671  0.0  \n",
       "11        6.134888      6.451753      6.793466  0.0  \n",
       "12        5.465948      5.520210      5.499982  0.0  \n",
       "13        5.395331      5.454787      5.557552  0.0  \n",
       "14        4.543295      4.605170      4.290459  0.0  \n",
       "15        7.641069      8.134765      8.607916  0.0  \n",
       "16        5.337538      5.497168      5.568345  0.0  \n",
       "17        4.523146      3.944006      0.000000  0.0  \n",
       "18        6.060582      6.240763      6.434747  0.0  \n",
       "19        6.198796      6.333335      6.652742  0.0  \n",
       "20        2.772589      0.000000      0.000000  0.0  \n",
       "21        4.762174      4.890349      4.969813  0.0  \n",
       "22        5.652489      5.831882      6.040255  0.0  \n",
       "23        2.708050      0.000000      0.000000  0.0  \n",
       "24        5.834811      6.077642      6.293419  0.0  \n",
       "25        7.157565      7.635515      8.018008  0.0  \n",
       "26        6.751321      7.048332      7.302612  0.0  \n",
       "27        4.848606      4.455074      4.352694  0.0  \n",
       "28        5.561162      5.568821      5.681878  0.0  \n",
       "29        6.151851      6.484856      6.339973  0.0  \n",
       "...            ...           ...           ...  ...  \n",
       "1075      7.294229      7.631557      8.007074  1.0  \n",
       "1076      6.591717      6.991033      7.274674  1.0  \n",
       "1077      6.631384      7.030719      7.325005  1.0  \n",
       "1078      6.455334      6.873095      6.939417  1.0  \n",
       "1079      6.333613      6.572807      6.736893  1.0  \n",
       "1080      3.218876      2.302585      0.000000  1.0  \n",
       "1081      6.272759      6.609097      6.919128  1.0  \n",
       "1082      7.288522      7.655010      8.058613  1.0  \n",
       "1083      6.545754      6.979000      7.346393  1.0  \n",
       "1084      6.681394      7.067183      7.171165  1.0  \n",
       "1085      5.365684      5.482980      5.400140  1.0  \n",
       "1086      5.728170      5.901779      5.917717  1.0  \n",
       "1087      4.104707      3.446011      3.056357  1.0  \n",
       "1088      6.771282      7.089077      7.031227  1.0  \n",
       "1089      4.743845      4.850075      4.323304  1.0  \n",
       "1090      4.066888      3.725693      2.784239  1.0  \n",
       "1091      7.460310      7.890512      8.276919  1.0  \n",
       "1092      5.865848      6.204873      6.369954  1.0  \n",
       "1093      5.358942      5.594479      5.380329  1.0  \n",
       "1094      4.150055      4.274928      4.123094  1.0  \n",
       "1095      7.327036      7.760788      8.122028  1.0  \n",
       "1096      5.805135      5.976351      6.091310  1.0  \n",
       "1097      5.403803      5.604422      5.480118  1.0  \n",
       "1098      6.654314      7.047680      7.348266  1.0  \n",
       "1099      6.711588      7.060610      7.424184  1.0  \n",
       "1100      4.320816      4.406719      4.342993  1.0  \n",
       "1101      5.960844      5.839187      5.411088  1.0  \n",
       "1102      5.495630      5.703366      5.926259  1.0  \n",
       "1103      6.065365      6.387320      5.916728  1.0  \n",
       "1104      6.335871      6.708575      6.648544  1.0  \n",
       "\n",
       "[1105 rows x 1525 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = _data_ = pd.read_csv('./data/train.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:09:35.534959Z",
     "start_time": "2018-05-01T11:09:35.230697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a4c6a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.y.unique())\n",
    "plt.hist(data.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:09:36.293907Z",
     "start_time": "2018-05-01T11:09:36.192663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "790 315 0.7149321266968326\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum().sum())\n",
    "\n",
    "num_1 = data[data.y == 1].shape[0] \n",
    "num_0 = data[data.y == 0].shape[0]\n",
    "\n",
    "print(num_1, num_0, num_1 / (num_0 + num_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:30:42.748177Z",
     "start_time": "2018-05-01T11:30:42.685156Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pp_pipeline(_data_)\n",
    "\n",
    "data_X = data.drop('y', axis=1)\n",
    "data_y = data[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:30:47.683880Z",
     "start_time": "2018-05-01T11:30:47.645036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y, test_X, test_y) = split_data2(data, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:09:57.467110Z",
     "start_time": "2018-05-01T11:09:56.647564Z"
    }
   },
   "outputs": [],
   "source": [
    "class DFS(BaseEstimator):\n",
    "    def __init__(self, layers_sizes=[128, 64, 2], batch_size=32, lambda1=1e-3, lambda2=1.,\n",
    "                 alpha1=1e-3, alpha2=0., num_epochs=10, verbose=0, N=None):\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.num_layers = len(layers_sizes)\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.num_epochs = num_epochs\n",
    "        self.verbose = verbose\n",
    "        self.N = N\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, test_data=None):\n",
    "        self._build_graph_(X.shape[1])\n",
    "        self.features = X.columns #Persisting for `select_most_important_ftrs`\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch_i in range(self.num_epochs):\n",
    "            X_cur = X.sample(frac=1, random_state=epoch_i)\n",
    "            y_cur = y.sample(frac=1, random_state=epoch_i)\n",
    "            epoch_loss = 0\n",
    "            for batch_X, batch_y in batch_data(X_cur, y_cur, \n",
    "                                               batch_size=self.batch_size):\n",
    "                train_loss, _ = self.sess.run([self.total_loss, self.train_step],\n",
    "                                               feed_dict = {self.x: batch_X,\n",
    "                                                            self.y: batch_y})\n",
    "                epoch_loss += train_loss\n",
    "            epoch_loss /= X.shape[0] // self.batch_size\n",
    "            \n",
    "            train_predict = self.predict(X_cur)\n",
    "            train_accuracy = mtcs.accuracy_score(y_cur, train_predict)\n",
    "            if self.verbose:\n",
    "                if test_data is not None:\n",
    "                    test_X, test_y = test_data\n",
    "                    test_predict = self.predict(test_X)\n",
    "                    test_accuracy = mtcs.accuracy_score(test_y, test_predict)\n",
    "                    print(f\"==> Epoch: {epoch_i}. Train loss: {epoch_loss}.\"\n",
    "                          f\"Train accuracy: {train_accuracy}. Test accuracy: {test_accuracy}.\")\n",
    "                else:\n",
    "                    print(f\"==> Epoch: {epoch_i}. Train loss: {epoch_loss}. \"\n",
    "                          f\"Train accuracy: {train_accuracy}.\")\n",
    "                \n",
    "        return self\n",
    "       \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions_proba = self.sess.run(self.predictions, feed_dict={self.x: X})\n",
    "        \n",
    "        return predictions_proba\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions_proba = self.predict_proba(X)\n",
    "        \n",
    "        return list(map(np.argmax, predictions_proba))\n",
    "    \n",
    "    \n",
    "    def get_features_weights(self):\n",
    "        weights = self.sess.run(self.features_weights)\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    \n",
    "    def select_most_important_ftrs(self, N):\n",
    "        weights = self.get_features_weights()\n",
    "        feature_weight = sorted(zip(weights, self.features), \n",
    "                                key=lambda x: abs(x[0]))\n",
    "        \n",
    "        return map(lambda x: x[1], feature_weight[-N:])\n",
    "    \n",
    "    \n",
    "    def transform(self, X, N=None):\n",
    "        if N:\n",
    "            features = list(self.select_most_important_ftrs(N))\n",
    "        else:\n",
    "            features = list(self.select_most_important_ftrs(self.N))\n",
    "        \n",
    "        return X[features]\n",
    "    \n",
    "     \n",
    "    def _build_graph_(self, num_features):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        ###Placeholders \n",
    "        x = tf.placeholder(tf.float32, [None, num_features], 'x_ph')\n",
    "        y = tf.placeholder(tf.int32, [None], 'y_ph')\n",
    "        \n",
    "        ###Weights initialization\n",
    "        w = tf.get_variable(\"dfs_features_weight\", \n",
    "                            initializer = tf.constant(1., shape=[num_features]))\n",
    "        self.layers_sizes = [num_features] + self.layers_sizes\n",
    "        W, b = [], []\n",
    "        for layer_i in range(self.num_layers):\n",
    "            W.append(weight_init(f\"layer_{layer_i}_weights\",\n",
    "                                 shape=[self.layers_sizes[layer_i],\n",
    "                                        self.layers_sizes[layer_i+1]]))\n",
    "            b.append(bias_init(f\"layer_{layer_i}_bias\",\n",
    "                               shape=[self.layers_sizes[layer_i+1]]))\n",
    "        \n",
    "        ###Input transformations\n",
    "        logits = x * w #feature selection\n",
    "        for layer_i in range(self.num_layers):\n",
    "            if layer_i != self.num_layers - 1:\n",
    "                logits = tf.nn.tanh(tf.matmul(logits, W[layer_i]) + b[layer_i])\n",
    "            else:\n",
    "                logits = tf.matmul(logits, W[layer_i]) + b[layer_i]\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "            \n",
    "        ###Loss calculation\n",
    "        logloss = tf.reduce_sum(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                                       logits=logits))\n",
    "        w_loss = elastic_net(w, self.lambda1, self.lambda2)\n",
    "        W_loss = tf.reduce_sum([elastic_net(W_i, self.alpha1, self.alpha2) for W_i in W])\n",
    "        \n",
    "        total_loss = tf.reduce_sum(logloss + w_loss + W_loss)\n",
    "        \n",
    "        ###Optimizer\n",
    "        train_step = tf.train.AdamOptimizer(0.001).minimize(total_loss)\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.predictions = predictions\n",
    "        self.total_loss = total_loss\n",
    "        self.train_step = train_step\n",
    "        self.features_weights = w\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:11:09.688053Z",
     "start_time": "2018-05-01T11:10:26.544871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFS(N=None, alpha1=0.001, alpha2=0.0, batch_size=32, lambda1=0.001,\n",
       "  lambda2=1.0, layers_sizes=[1524, 128, 64, 2], num_epochs=200, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = DFS([128, 64, 2], num_epochs=200)\n",
    "\n",
    "dfs.fit(train_X, train_y['y'], test_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:01.984037Z",
     "start_time": "2018-05-01T11:13:01.712596Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 149.,    7.,    6.,   16.,   26.,  237.,  703.,  312.,   53.,   15.]),\n",
       " array([ -2.71258759e-04,   1.15846904e-01,   2.31965067e-01,\n",
       "          3.48083229e-01,   4.64201392e-01,   5.80319555e-01,\n",
       "          6.96437717e-01,   8.12555880e-01,   9.28674043e-01,\n",
       "          1.04479221e+00,   1.16091037e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a4afc2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dfs.get_features_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:39:14.303005Z",
     "start_time": "2018-05-01T11:39:14.207008Z"
    }
   },
   "outputs": [],
   "source": [
    "class LassoFS(BaseEstimator):\n",
    "    def __init__(self, N=None):\n",
    "        self.N = N\n",
    "        self.est = lm.LogisticRegression(penalty='l1')\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.est.fit(X, y)\n",
    "        self.features = train_X.columns\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, N=None):\n",
    "        if N:\n",
    "            features = list(self.select_most_important_ftrs(N))\n",
    "        else:\n",
    "            features = list(self.select_most_important_ftrs(self.N))\n",
    "        \n",
    "        return X[features]\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.est.predict(X)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.est.coef_\n",
    "\n",
    "\n",
    "    def select_most_important_ftrs(self, N):\n",
    "        feature_weight = sorted(zip(self.est.coef_[0], self.features),\n",
    "                                key=lambda x: abs(x[0]))\n",
    "\n",
    "        return list(map(lambda x: x[1], feature_weight[-N:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:09.345422Z",
     "start_time": "2018-05-01T11:13:08.627158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841628959276\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a356e518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est = LassoFS();\n",
    "est.fit(train_X, train_y.y);\n",
    "print(mtcs.accuracy_score(test_y, est.predict(test_X)))\n",
    "plt.hist(est.coef_[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:12.485781Z",
     "start_time": "2018-05-01T11:13:12.378210Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForestFS(BaseEstimator):\n",
    "    def __init__(self, N=None):\n",
    "        self.N = N\n",
    "        self.est = ens.RandomForestClassifier()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.est.fit(X, y)\n",
    "        self.features = X.columns\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, N=None):\n",
    "        if N:\n",
    "            features = self.select_most_important_ftrs(N)\n",
    "        else:\n",
    "            features = self.select_most_important_ftrs(self.N)\n",
    "            \n",
    "        return X[features]\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.est.predict(X)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.est.feature_importances_\n",
    "    \n",
    "    \n",
    "    def select_most_important_ftrs(self, N):\n",
    "        feature_weight = sorted( zip(self.est.feature_importances_,\n",
    "                                     self.features),\n",
    "                                 key=lambda x: x[0])\n",
    "        return list(map(lambda x: x[1], feature_weight[-N:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:14.021062Z",
     "start_time": "2018-05-01T11:13:13.594430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877828054299\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a345ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est = RandomForestFS();\n",
    "est.fit(train_X, train_y);\n",
    "print(mtcs.accuracy_score(test_y, est.predict(test_X)))\n",
    "plt.hist(est.feature_importances_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:51.343741Z",
     "start_time": "2018-05-01T11:13:51.119748Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = ens.RandomForestClassifier()\n",
    "\n",
    "train_X_dfs = dfs.transform(train_X, 500)\n",
    "test_X_dfs = dfs.transform(test_X, 500)\n",
    "\n",
    "est.fit(train_X_dfs, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:51.855422Z",
     "start_time": "2018-05-01T11:13:51.842145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85520361990950222"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcs.accuracy_score(test_y, est.predict(test_X_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:13:53.340357Z",
     "start_time": "2018-05-01T11:13:53.313800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dfa74bf39734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_p' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(acc_p)\n",
    "plt.show()\n",
    "plt.hist(acc_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T16:30:31.617460Z",
     "start_time": "2018-04-30T16:30:31.607461Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8637867739884362, 0.062351653820433672)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest(acc_p, acc_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def select_most_important_ftrs(est, features, N):\n",
    "    feature_weight = sorted(zip(est.coef_[0], features),\n",
    "                            key=lambda x: abs(x[0]))\n",
    "    \n",
    "    return list(map(lambda x: x[1], feature_weight[-N:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T16:50:43.173156Z",
     "start_time": "2018-04-30T16:49:42.223366Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=40, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=False, subsample=1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = XGBClassifier(n_estimators=1000, n_jobs=40, silent=False)\n",
    "\n",
    "est.fit(train_X_dfs, train_y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T16:46:40.858161Z",
     "start_time": "2018-04-30T16:46:40.800863Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876811594202898"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcs.accuracy_score(test_y, est.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T16:46:44.087000Z",
     "start_time": "2018-04-30T16:46:44.049767Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:50:34.787798Z",
     "start_time": "2018-05-01T11:50:34.779037Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = [10, 50, 100, 150, 200, 250, 300, 350, 400, 500, 750, 1000,  ALL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:50:37.016182Z",
     "start_time": "2018-05-01T11:50:36.977074Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(main_model, feature_selector, param_grid, \n",
    "             X, y, scoring='accuracy', caching=False):\n",
    "\n",
    "    if main_model is not None:\n",
    "        pipeline_list = [('select_ftrs', feature_selector),\n",
    "                         ('main', main_model)]\n",
    "    else:\n",
    "        pipeline_list = [('select_ftrs', feature_selector)]\n",
    "\n",
    "    if caching:\n",
    "        pipeline = Pipeline(pipeline_list, memory=mkdtemp())\n",
    "    else:\n",
    "        pipeline = Pipeline(pipeline_list)\n",
    "    \n",
    "    grid = ms.GridSearchCV(pipeline, cv=ms.StratifiedKFold(shuffle=True),\n",
    "                           n_jobs=1, param_grid=param_grid,\n",
    "                           verbose=100, scoring=scoring)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:50:38.164877Z",
     "start_time": "2018-05-01T11:50:38.129354Z"
    }
   },
   "outputs": [],
   "source": [
    "all_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:52:33.512117Z",
     "start_time": "2018-05-01T11:50:40.483506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8184281842818428, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ................... select_ftrs__N=10, score=0.875, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8505434782608695, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8563685636856369, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ....... select_ftrs__N=50, score=0.842391304347826, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8668478260869565, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8590785907859079, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   19.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8831521739130435, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   21.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8369565217391305, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   25.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8644986449864499, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8641304347826086, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   30.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8559782608695652, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   33.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8455284552845529, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   36.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ...... select_ftrs__N=200, score=0.907608695652174, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   39.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] .................. select_ftrs__N=200, score=0.875, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   41.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8238482384823849, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   44.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8722826086956522, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   47.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8586956521739131, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   50.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8455284552845529, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   53.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8804347826086957, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   56.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8396739130434783, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   58.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8373983739837398, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8668478260869565, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8668478260869565, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8536585365853658, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8777173913043478, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8505434782608695, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8455284552845529, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8777173913043478, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8831521739130435, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8482384823848238, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8614130434782609, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8369565217391305, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8265582655826558, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8614130434782609, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8505434782608695, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8617886178861789, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... select_ftrs__N=1524, score=0.8614130434782609, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8396739130434783, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "##### DFS + RandomForest #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N': NUM_FEATURES\n",
    "#      'select_ftrs__lambda1': np.arange(0, 0.05, 0.005)\n",
    "#      'main__n_estimators': [10, 25, 50]\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['DFS + RF'] = evaluate(ens.RandomForestClassifier(),\n",
    "                                  DFS(), param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:55:24.035558Z",
     "start_time": "2018-05-01T11:52:33.516053Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8238482384823849, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8722826086956522, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8559782608695652, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8590785907859079, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ....... select_ftrs__N=50, score=0.842391304347826, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8913043478260869, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   17.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8428184281842819, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   19.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8940217391304348, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   23.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8885869565217391, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   26.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8482384823848238, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   29.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8831521739130435, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   32.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8777173913043478, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   36.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8563685636856369, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   39.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.9103260869565217, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   43.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8967391304347826, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   46.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8455284552845529, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   50.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8967391304347826, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   53.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8858695652173914, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   56.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8563685636856369, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8722826086956522, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8777173913043478, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8536585365853658, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ...... select_ftrs__N=350, score=0.904891304347826, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] .................. select_ftrs__N=350, score=0.875, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8509485094850948, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8940217391304348, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8777173913043478, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8563685636856369, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8940217391304348, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8858695652173914, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8455284552845529, total=   5.3s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8831521739130435, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8858695652173914, total=   5.3s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8455284552845529, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8777173913043478, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8777173913043478, total=   6.3s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8536585365853658, total=   8.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... select_ftrs__N=1524, score=0.8885869565217391, total=   8.1s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8858695652173914, total=   7.7s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "##### DFS + Gradient Boosting #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N': NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['DFS + GB'] = evaluate(XGBClassifier(),\n",
    "                                  DFS(), param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:55:39.897186Z",
     "start_time": "2018-05-01T11:55:24.039739Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8834688346883469, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ................... select_ftrs__N=10, score=0.875, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8260869565217391, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8970189701897019, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8641304347826086, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8586956521739131, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8915989159891599, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8505434782608695, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8233695652173914, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8726287262872628, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8505434782608695, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    4.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ...... select_ftrs__N=150, score=0.845108695652174, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8834688346883469, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    4.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8559782608695652, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    5.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8668478260869565, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    5.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8726287262872628, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    6.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8559782608695652, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    6.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8831521739130435, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    6.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8834688346883469, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    7.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8695652173913043, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    7.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8478260869565217, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    7.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8753387533875339, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    8.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8559782608695652, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    8.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8505434782608695, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    8.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8888888888888888, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8858695652173914, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    9.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8614130434782609, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   10.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8699186991869918, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   10.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ...... select_ftrs__N=500, score=0.842391304347826, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   10.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8505434782608695, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   11.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8834688346883469, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   11.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8695652173913043, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   12.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8206521739130435, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   12.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8753387533875339, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   12.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8043478260869565, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   13.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8478260869565217, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   13.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8726287262872628, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   14.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... select_ftrs__N=1524, score=0.845108695652174, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   14.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8260869565217391, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   15.2s finished\n"
     ]
    }
   ],
   "source": [
    "##### LassoFS + RandomForest #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N':  NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['Lasso + RF'] =  evaluate(ens.RandomForestClassifier(),\n",
    "                                     LassoFS(), param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:56:45.606616Z",
     "start_time": "2018-05-01T11:55:39.899827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8644986449864499, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8614130434782609, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8641304347826086, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8726287262872628, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8804347826086957, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8586956521739131, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8590785907859079, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] .................. select_ftrs__N=100, score=0.875, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8777173913043478, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8726287262872628, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8804347826086957, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    6.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8831521739130435, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    6.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8807588075880759, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    7.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8804347826086957, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    8.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8777173913043478, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    9.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8780487804878049, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   10.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8804347826086957, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   11.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] .................. select_ftrs__N=250, score=0.875, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   12.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8807588075880759, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   13.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] .................. select_ftrs__N=300, score=0.875, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   14.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8913043478260869, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   15.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8780487804878049, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   16.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] .................. select_ftrs__N=350, score=0.875, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   17.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8858695652173914, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   19.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8861788617886179, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   20.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] .................. select_ftrs__N=400, score=0.875, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   21.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8804347826086957, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   22.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8780487804878049, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   24.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8804347826086957, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   26.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8777173913043478, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   27.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8807588075880759, total=   2.3s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   30.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8913043478260869, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   32.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8777173913043478, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   34.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8861788617886179, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   38.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8777173913043478, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   41.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8804347826086957, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   44.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8780487804878049, total=   5.6s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   50.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... select_ftrs__N=1524, score=0.8858695652173914, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   55.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8614130434782609, total=   6.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "##### LassoFS + GradientBoosting #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N':  NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['Lasso + GB'] = evaluate(XGBClassifier(),\n",
    "                                    LassoFS(), param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:58:31.710456Z",
     "start_time": "2018-05-01T11:56:45.609089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8699186991869918, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8478260869565217, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8505434782608695, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8672086720867209, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ....... select_ftrs__N=50, score=0.842391304347826, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8586956521739131, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8644986449864499, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   18.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ...... select_ftrs__N=100, score=0.845108695652174, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   21.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8505434782608695, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   24.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8590785907859079, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8559782608695652, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   29.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8369565217391305, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   31.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8644986449864499, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   34.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ...... select_ftrs__N=200, score=0.845108695652174, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   37.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8586956521739131, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   39.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8726287262872628, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   42.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8532608695652174, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   44.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ...... select_ftrs__N=250, score=0.842391304347826, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   47.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8644986449864499, total=   2.3s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   49.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8478260869565217, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   52.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8369565217391305, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   54.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8726287262872628, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   57.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8641304347826086, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ...... select_ftrs__N=350, score=0.845108695652174, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8672086720867209, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8614130434782609, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8478260869565217, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8536585365853658, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8614130434782609, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8369565217391305, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8672086720867209, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ...... select_ftrs__N=750, score=0.842391304347826, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ...... select_ftrs__N=750, score=0.845108695652174, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8617886178861789, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] ..... select_ftrs__N=1000, score=0.842391304347826, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8668478260869565, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8482384823848238, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... select_ftrs__N=1524, score=0.8260869565217391, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8315217391304348, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "##### Pure DFS #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N':  NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['DFS'] = evaluate(None, DFS(),\n",
    "                             param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T11:58:46.467533Z",
     "start_time": "2018-05-01T11:58:31.714450Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8586956521739131, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8152173913043478, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8586956521739131, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n",
      "[CV] ...... select_ftrs__N=50, score=0.8152173913043478, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8617886178861789, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8179347826086957, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    4.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8179347826086957, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8644986449864499, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    4.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    5.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8179347826086957, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    5.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    5.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    6.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8152173913043478, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    6.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    6.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    7.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8152173913043478, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    7.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    7.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    8.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8179347826086957, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    8.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8644986449864499, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    8.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    9.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8179347826086957, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    9.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    9.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   10.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8179347826086957, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   10.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   10.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   11.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8152173913043478, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   11.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   12.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8586956521739131, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   12.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8179347826086957, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   12.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8644986449864499, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   13.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... select_ftrs__N=1524, score=0.8586956521739131, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   13.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8179347826086957, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   14.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   14.0s finished\n"
     ]
    }
   ],
   "source": [
    "##### Pure Lasso #####\n",
    "param_grid = [\n",
    "    {\n",
    "     'select_ftrs__N':  NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['Lasso'] = evaluate( None, LassoFS(),\n",
    "                             param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:18:41.215935Z",
     "start_time": "2018-05-01T12:15:06.994248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=10, score=0.8644986449864499, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n",
      "[CV] ...... select_ftrs__N=10, score=0.8179347826086957, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=10, score=0.8342391304347826, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   11.7s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8617886178861789, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   16.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8641304347826086, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   20.5s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8695652173913043, total=   3.8s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   24.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8672086720867209, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   28.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8641304347826086, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   32.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8668478260869565, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   37.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8617886178861789, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8804347826086957, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   45.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8777173913043478, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   49.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8780487804878049, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   55.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8722826086956522, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   59.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8614130434782609, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8888888888888888, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] .................. select_ftrs__N=250, score=0.875, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8695652173913043, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8726287262872628, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8614130434782609, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8668478260869565, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8672086720867209, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8722826086956522, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8804347826086957, total=   5.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8699186991869918, total=   5.5s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8614130434782609, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8668478260869565, total=   5.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8753387533875339, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] .................. select_ftrs__N=500, score=0.875, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8777173913043478, total=   6.1s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8644986449864499, total=   6.3s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8641304347826086, total=   6.2s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8722826086956522, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  2.7min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8753387533875339, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8641304347826086, total=   7.8s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] ................. select_ftrs__N=1000, score=0.875, total=   6.1s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8726287262872628, total=   8.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8777173913043478, total=   9.5s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  3.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8777173913043478, total=   8.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  3.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "##### DFS + MLP #####\n",
    "param_grid = [\n",
    "    {\n",
    "        'select_ftrs__N': NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['DFS + MLP'] = evaluate(nn.MLPClassifier(), DFS(),\n",
    "                                   param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:21:30.794046Z",
     "start_time": "2018-05-01T12:19:43.494041Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13 candidates, totalling 39 fits\n",
      "[CV] select_ftrs__N=10 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=10, score=0.8590785907859079, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=10, score=0.8532608695652174, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=10 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=10, score=0.8478260869565217, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8617886178861789, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8315217391304348, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=50 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... select_ftrs__N=50, score=0.8559782608695652, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8536585365853658, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8505434782608695, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=100 ..............................................\n",
      "[CV] ..... select_ftrs__N=100, score=0.8478260869565217, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8644986449864499, total=   1.7s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8532608695652174, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   15.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=150 ..............................................\n",
      "[CV] ..... select_ftrs__N=150, score=0.8478260869565217, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   17.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8563685636856369, total=   1.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   19.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8369565217391305, total=   1.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   21.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=200 ..............................................\n",
      "[CV] ..... select_ftrs__N=200, score=0.8559782608695652, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   23.2s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8699186991869918, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   25.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ...... select_ftrs__N=250, score=0.845108695652174, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   27.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=250 ..............................................\n",
      "[CV] ..... select_ftrs__N=250, score=0.8505434782608695, total=   1.7s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   28.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8536585365853658, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   31.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8478260869565217, total=   1.8s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   32.9s remaining:    0.0s\n",
      "[CV] select_ftrs__N=300 ..............................................\n",
      "[CV] ..... select_ftrs__N=300, score=0.8668478260869565, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   35.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8644986449864499, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   37.6s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ...... select_ftrs__N=350, score=0.845108695652174, total=   2.4s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   40.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=350 ..............................................\n",
      "[CV] ..... select_ftrs__N=350, score=0.8586956521739131, total=   2.3s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   42.4s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8563685636856369, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   45.1s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8342391304347826, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   47.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=400 ..............................................\n",
      "[CV] ..... select_ftrs__N=400, score=0.8586956521739131, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   49.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8644986449864499, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   53.3s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ...... select_ftrs__N=500, score=0.845108695652174, total=   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   56.0s remaining:    0.0s\n",
      "[CV] select_ftrs__N=500 ..............................................\n",
      "[CV] ..... select_ftrs__N=500, score=0.8695652173913043, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   58.8s remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8644986449864499, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8586956521739131, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] select_ftrs__N=750 ..............................................\n",
      "[CV] ..... select_ftrs__N=750, score=0.8559782608695652, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8509485094850948, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8586956521739131, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1000 .............................................\n",
      "[CV] .... select_ftrs__N=1000, score=0.8586956521739131, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8753387533875339, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8478260869565217, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] select_ftrs__N=1524 .............................................\n",
      "[CV] .... select_ftrs__N=1524, score=0.8695652173913043, total=   5.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "##### Lasso + MLP #####\n",
    "param_grid = [\n",
    "    {\n",
    "        'select_ftrs__N': NUM_FEATURES\n",
    "    }\n",
    "]\n",
    "\n",
    "all_scores['Lasso + MLP'] = evaluate(nn.MLPClassifier(), LassoFS(),\n",
    "                                   param_grid, data_X, data_y.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:22:00.075614Z",
     "start_time": "2018-05-01T12:22:00.067412Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = {'DFS + RF': 'blue',\n",
    "          'DFS + GB': 'green',\n",
    "          'Lasso + RF': 'red',\n",
    "          'Lasso + GB': 'pink',\n",
    "          'DFS': 'brown',\n",
    "          'Lasso': 'orange',\n",
    "          'DFS + MLP': 'greenyellow',\n",
    "          'Lasso + MLP': 'cyan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:22:00.722202Z",
     "start_time": "2018-05-01T12:22:00.621418Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_scores(all_scores, experiment):\n",
    "    param_id = dict()\n",
    "    cur_results = all_scores[experiment].cv_results_\n",
    "\n",
    "    for i, params in enumerate(cur_results['params']):\n",
    "        key = params['select_ftrs__N']\n",
    "        if key in param_id:\n",
    "            param_id[key].append(i)\n",
    "        else:\n",
    "            param_id[key] = [i]\n",
    "\n",
    "    max_test_score = {}\n",
    "    all_test_scores = {}\n",
    "    for ts in param_id.keys():\n",
    "        all_test_scores[ts] = cur_results['mean_test_score'][param_id[ts]]\n",
    "        max_test_score[ts] = max(all_test_scores[ts])\n",
    "    \n",
    "    return max_test_score, all_test_scores\n",
    "\n",
    "def plot(all_scores):\n",
    "    p = figure(plot_width=1000)\n",
    "    for i, score_title in enumerate(all_scores):\n",
    "        max_scores, _ = get_test_scores(all_scores, score_title)\n",
    "        \n",
    "        p.line(x = list(max_scores.keys()), \n",
    "               y = list(max_scores.values()),\n",
    "               legend=score_title,\n",
    "               line_color=colors[score_title])\n",
    "        p.circle(x = list(max_scores.keys()), \n",
    "               y = list(max_scores.values()),\n",
    "               legend=score_title,\n",
    "               color=colors[score_title],\n",
    "               alpha=1.)\n",
    "        \n",
    "    \n",
    "    p.legend.location = 'bottom_right'\n",
    "    p.legend.click_policy = 'hide'\n",
    "\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:22:02.016261Z",
     "start_time": "2018-05-01T12:22:01.305874Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"0cef2233-c428-4bc2-82e8-ea5c952f9e1a\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"f01e372e-5e27-4b54-9193-21b12a40cd71\":{\"roots\":{\"references\":[{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8479638009049774,0.8552036199095022,0.8597285067873304,0.8615384615384616,0.8760180995475113,0.8515837104072398,0.8552036199095022,0.8570135746606334,0.860633484162896,0.8687782805429864,0.848868778280543,0.8461538461538461,0.8542986425339366]}},\"id\":\"11271fa5-9622-4991-b53f-4f8571864493\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"overlay\":{\"id\":\"7c0b2d96-2ccc-47d3-b8fd-23ff0bf115a0\",\"type\":\"BoxAnnotation\"}},\"id\":\"0a291670-9e5c-4ec0-a4ea-9828f92fc330\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"03205fd6-9624-419f-8eab-c9d3aba56785\",\"type\":\"Line\"},{\"attributes\":{\"fill_color\":{\"value\":\"brown\"},\"line_color\":{\"value\":\"brown\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"bb735e35-f169-40e1-9d9d-3ebe4b583304\",\"type\":\"Circle\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"7c0b2d96-2ccc-47d3-b8fd-23ff0bf115a0\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"0864a354-2a99-4af9-b029-b7b5c5fd5f0b\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"blue\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"6bca5fc8-8ef4-460a-9ca1-301ff1031522\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"cd1b624a-f44a-4179-86a5-9072a23f9867\",\"type\":\"ColumnDataSource\"}},\"id\":\"f871763b-ae40-4a02-87fb-e363d0744728\",\"type\":\"CDSView\"},{\"attributes\":{\"label\":{\"value\":\"DFS + MLP\"},\"renderers\":[{\"id\":\"bbad7a9a-d59e-4f00-95a2-d6c5a9b6ed27\",\"type\":\"GlyphRenderer\"},{\"id\":\"27dd07fe-f4f7-44f0-994a-c76ab55a9dd6\",\"type\":\"GlyphRenderer\"}]},\"id\":\"35419a66-41fc-492c-93ef-efb964e964c5\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"e94543b1-1471-4238-a026-d32fd1837b34\",\"type\":\"ColumnDataSource\"}},\"id\":\"1db9c1ee-c832-4f7f-8d0a-636d384e67df\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"pink\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"729d109c-be65-4384-b1a8-d88f8746be58\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"d3462164-b928-442b-9e8f-5e18696be405\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d89b4a83-489f-4eae-8f3b-7d4307172ddf\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"64619bee-2e0b-4396-acca-8bcf5d73bcbe\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"7abaac03-e7dd-4251-9ea8-4aa518f5e65d\",\"type\":\"CDSView\"}},\"id\":\"887899f0-ea14-40fb-8657-3b876911f8ee\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"ff40040b-400e-46e6-82e3-d1b5709610f9\",\"type\":\"PanTool\"},{\"id\":\"1bf9b1c8-0264-4bbe-9e07-b40528f59a82\",\"type\":\"WheelZoomTool\"},{\"id\":\"0a291670-9e5c-4ec0-a4ea-9828f92fc330\",\"type\":\"BoxZoomTool\"},{\"id\":\"f2fbcfb0-ac31-48ba-bf5c-035bdc148579\",\"type\":\"SaveTool\"},{\"id\":\"e084428b-a14b-4aae-b91b-c43bff28f59e\",\"type\":\"ResetTool\"},{\"id\":\"ca26aa4e-1219-4352-8c99-33e2650eb913\",\"type\":\"HelpTool\"}]},\"id\":\"bafbfa38-016f-4775-ae24-fce9c7fe71c0\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"e9eb1d57-57b4-4455-9c03-ae0dc59cb1d2\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"ca4aa81b-73d0-4d3b-b6d5-9122d4d2bf37\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"cbdd194b-2649-49ce-89b0-9160c2e48f0d\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"32eb7c49-f556-4397-989e-1dbbaeac7143\",\"type\":\"CDSView\"}},\"id\":\"58d2d5b8-97a6-4d31-952c-218b115e3c59\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_color\":{\"value\":\"red\"},\"line_color\":{\"value\":\"red\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"f932741e-a4a0-4685-8883-e59f29bd1b91\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8389140271493213,0.865158371040724,0.8660633484162896,0.8733031674208145,0.8705882352941177,0.8778280542986425,0.8669683257918552,0.8733031674208145,0.8660633484162896,0.8760180995475113,0.8669683257918552,0.8714932126696833,0.8760180995475113]}},\"id\":\"62c5e922-0586-4db9-b057-baf8b88dc94b\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"aaf27988-bc94-4b8c-838f-e0505b371f7e\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"c1d0cc60-36eb-4e2b-95b6-9225b1ede669\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"bb735e35-f169-40e1-9d9d-3ebe4b583304\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"40480718-c4bc-4005-99e8-522780716da9\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"145e0ccd-2cd8-403b-9dae-a28ae86911de\",\"type\":\"CDSView\"}},\"id\":\"10ffeef8-f1e3-47d1-9dae-87a14ee27337\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8615384615384616,0.8733031674208145,0.8552036199095022,0.8561085972850678,0.8687782805429864,0.8705882352941177,0.8669683257918552,0.860633484162896,0.8787330316742081,0.8542986425339366,0.857918552036199,0.8425339366515837,0.8479638009049774]}},\"id\":\"f44e752d-6cfd-4b39-9ff4-d8217fb9c414\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"331ecd5d-e229-4172-a498-7cbfb795be0b\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a6ac5ea1-4313-4e35-807f-3de2318bb7da\",\"type\":\"BasicTicker\"}},\"id\":\"38ed5cca-da7d-4815-990d-0aef52f59193\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"cd1b624a-f44a-4179-86a5-9072a23f9867\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"757e86ff-2653-4a77-a0ee-ce726230daf0\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"41bab839-1473-4d2b-ab93-2d5bab270f55\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"f871763b-ae40-4a02-87fb-e363d0744728\",\"type\":\"CDSView\"}},\"id\":\"23e2ae0c-d7bc-4cec-b9ab-b6ddaf64e872\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_color\":\"red\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"89463def-7193-4fc9-a586-f877edf4bba2\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"green\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"15bbc2db-6112-4cd0-a8d7-c88de19115c0\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Lasso + GB\"},\"renderers\":[{\"id\":\"00a75378-3647-4f32-b87d-ec237669436d\",\"type\":\"GlyphRenderer\"},{\"id\":\"0c2f7411-7fcc-4ab2-8249-835269a06840\",\"type\":\"GlyphRenderer\"}]},\"id\":\"4a7fea8a-d657-4597-a2de-a89fec6a4701\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1e1c6a17-27da-446e-8ba4-283e40064720\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"b56e5994-2deb-465e-bf15-649e67a0722c\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"62c5e922-0586-4db9-b057-baf8b88dc94b\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"9ca400af-3afc-49cd-8b8d-a12f2343131b\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"0864a354-2a99-4af9-b029-b7b5c5fd5f0b\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"f5456d1b-14d4-43ac-8509-132683c243c7\",\"type\":\"CDSView\"}},\"id\":\"bbad7a9a-d59e-4f00-95a2-d6c5a9b6ed27\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8389140271493213,0.865158371040724,0.8660633484162896,0.8733031674208145,0.8705882352941177,0.8778280542986425,0.8669683257918552,0.8733031674208145,0.8660633484162896,0.8760180995475113,0.8669683257918552,0.8714932126696833,0.8760180995475113]}},\"id\":\"76bd7944-453c-496e-9bcb-27c6ffe48ad6\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.853393665158371,0.8497737556561086,0.8506787330316742,0.8552036199095022,0.8497737556561086,0.8552036199095022,0.8561085972850678,0.8561085972850678,0.8497737556561086,0.8597285067873304,0.8597285067873304,0.8561085972850678,0.8642533936651584]}},\"id\":\"ef17ae49-b17f-4284-ac4c-df9bd76b5a38\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8633484162895928,0.8705882352941177,0.8705882352941177,0.8787330316742081,0.8796380090497737,0.8778280542986425,0.8823529411764706,0.8796380090497737,0.8805429864253393,0.8787330316742081,0.8832579185520362,0.881447963800905,0.8751131221719457]}},\"id\":\"6cb86b35-17c8-47e4-8647-280b36f4b400\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"ca26aa4e-1219-4352-8c99-33e2650eb913\",\"type\":\"HelpTool\"},{\"attributes\":{\"data_source\":{\"id\":\"07df2f47-fa2a-4ad2-9b98-ebd848fe646c\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1995c00e-4fa7-4852-95a3-22109482f1bf\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ee68f141-e453-41c8-8af3-658d2157d7dd\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"840ea320-bb25-4390-8bb7-e2a404fa1705\",\"type\":\"CDSView\"}},\"id\":\"69e8142c-9da0-4832-9ff0-649c701d16cf\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_color\":\"greenyellow\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"9ca400af-3afc-49cd-8b8d-a12f2343131b\",\"type\":\"Line\"},{\"attributes\":{\"fill_color\":{\"value\":\"pink\"},\"line_color\":{\"value\":\"pink\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"82f99764-5a28-4080-a648-279eb25a5b74\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"f2fbcfb0-ac31-48ba-bf5c-035bdc148579\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8506787330316742,0.8642533936651584,0.8751131221719457,0.869683257918552,0.8877828054298642,0.8760180995475113,0.8687782805429864,0.8778280542986425,0.8742081447963801,0.8787330316742081,0.8714932126696833,0.8669683257918552,0.8760180995475113]}},\"id\":\"3dcd023e-f25a-49ea-9889-4fa85f8bd4ae\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"4b842f65-6f1d-4213-b338-4f5462b35332\",\"type\":\"ColumnDataSource\"}},\"id\":\"05f4a4cf-cbcc-46cb-9ea3-72cebf9b370d\",\"type\":\"CDSView\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"ef3adefc-2874-4745-9990-d21f7b6196c9\",\"type\":\"LegendItem\"},{\"id\":\"c4d8431c-3ce4-486d-a116-7d8f4807340d\",\"type\":\"LegendItem\"},{\"id\":\"e814fc66-1b58-434e-9982-8a9ec2c9d04a\",\"type\":\"LegendItem\"},{\"id\":\"4a7fea8a-d657-4597-a2de-a89fec6a4701\",\"type\":\"LegendItem\"},{\"id\":\"d8fe8de3-153c-423e-bb2c-482ac9ebb71b\",\"type\":\"LegendItem\"},{\"id\":\"31c9bc27-606c-4c73-ade0-9ad85b66e1a1\",\"type\":\"LegendItem\"},{\"id\":\"35419a66-41fc-492c-93ef-efb964e964c5\",\"type\":\"LegendItem\"},{\"id\":\"3f7fd5f9-a4d3-4482-a0eb-fa451eaaafcc\",\"type\":\"LegendItem\"}],\"location\":\"bottom_right\",\"plot\":{\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"26149ed5-3cac-436e-bce4-9e6e5f3f3d5a\",\"type\":\"Legend\"},{\"attributes\":{\"source\":{\"id\":\"539a4421-ffa1-48cc-b338-b93669ba479c\",\"type\":\"ColumnDataSource\"}},\"id\":\"4eee1c21-12f3-4fb3-87df-0eca7b5564c5\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"76bd7944-453c-496e-9bcb-27c6ffe48ad6\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"f180b434-6d93-417e-8148-6f1d8c2c6193\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ea3d55dd-0eac-4f6e-8e06-6eef74647027\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"30c06095-ee8b-480d-846a-bfb61445ff8a\",\"type\":\"CDSView\"}},\"id\":\"27dd07fe-f4f7-44f0-994a-c76ab55a9dd6\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"ff40040b-400e-46e6-82e3-d1b5709610f9\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8615384615384616,0.8733031674208145,0.8552036199095022,0.8561085972850678,0.8687782805429864,0.8705882352941177,0.8669683257918552,0.860633484162896,0.8787330316742081,0.8542986425339366,0.857918552036199,0.8425339366515837,0.8479638009049774]}},\"id\":\"b3b71a42-2436-4c17-aacb-55eb4390786f\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"c1d0cc60-36eb-4e2b-95b6-9225b1ede669\",\"type\":\"ColumnDataSource\"}},\"id\":\"145e0ccd-2cd8-403b-9dae-a28ae86911de\",\"type\":\"CDSView\"},{\"attributes\":{\"formatter\":{\"id\":\"6ed7d124-bd5e-4447-ae97-f3901b640523\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"271a3c02-9739-4a30-9376-6eb5d126d657\",\"type\":\"BasicTicker\"}},\"id\":\"95b1f671-4b09-410f-834e-b1315359c43b\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.853393665158371,0.8497737556561086,0.8506787330316742,0.8552036199095022,0.8497737556561086,0.8552036199095022,0.8561085972850678,0.8561085972850678,0.8497737556561086,0.8597285067873304,0.8597285067873304,0.8561085972850678,0.8642533936651584]}},\"id\":\"cd1b624a-f44a-4179-86a5-9072a23f9867\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"ef17ae49-b17f-4284-ac4c-df9bd76b5a38\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"eb7c37f5-1ef5-421c-a554-a746c79db393\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"031fa2c8-cacc-4039-a7a9-215aeadfc4a8\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"43b623df-2f68-477c-a37e-a993b0940877\",\"type\":\"CDSView\"}},\"id\":\"5bc94e25-45f5-4d08-8d8b-641f7c59b025\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"271a3c02-9739-4a30-9376-6eb5d126d657\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"green\"},\"line_color\":{\"value\":\"green\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"bb176afd-6114-4f2b-9262-7baef3a7cff0\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8461538461538461,0.8461538461538461,0.8461538461538461,0.8470588235294118,0.8470588235294118,0.8461538461538461,0.8461538461538461,0.8470588235294118,0.8470588235294118,0.8470588235294118,0.8461538461538461,0.8470588235294118,0.8470588235294118]}},\"id\":\"e94543b1-1471-4238-a026-d32fd1837b34\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"9b65a743-bd71-42cb-988e-b3bb2cc79e1b\",\"type\":\"Circle\"},{\"attributes\":{\"source\":{\"id\":\"b3b71a42-2436-4c17-aacb-55eb4390786f\",\"type\":\"ColumnDataSource\"}},\"id\":\"e74ef68f-2e0d-40cc-aef3-8c36cc9b184c\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"b3b71a42-2436-4c17-aacb-55eb4390786f\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"89463def-7193-4fc9-a586-f877edf4bba2\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"03205fd6-9624-419f-8eab-c9d3aba56785\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"e74ef68f-2e0d-40cc-aef3-8c36cc9b184c\",\"type\":\"CDSView\"}},\"id\":\"679d46fb-191c-4b77-96da-e44fe6d23fc4\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8561085972850678,0.8561085972850678,0.853393665158371,0.8506787330316742,0.8561085972850678,0.8561085972850678,0.8497737556561086,0.860633484162896,0.8588235294117647,0.8506787330316742,0.8515837104072398,0.8570135746606334,0.8352941176470589]}},\"id\":\"07df2f47-fa2a-4ad2-9b98-ebd848fe646c\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1bf9b1c8-0264-4bbe-9e07-b40528f59a82\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"3dcd023e-f25a-49ea-9889-4fa85f8bd4ae\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"15bbc2db-6112-4cd0-a8d7-c88de19115c0\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1e1c6a17-27da-446e-8ba4-283e40064720\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"007f9062-7908-4b31-83e6-4f4baa279336\",\"type\":\"CDSView\"}},\"id\":\"d3cabbc5-56f2-4cbe-abf9-c657d52c0010\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null},\"id\":\"143c1667-042f-4bde-abaf-54062fd2638d\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"e94543b1-1471-4238-a026-d32fd1837b34\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"beaa5734-056f-435d-a9bd-bd4d069e46cf\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"b56e5994-2deb-465e-bf15-649e67a0722c\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"1db9c1ee-c832-4f7f-8d0a-636d384e67df\",\"type\":\"CDSView\"}},\"id\":\"ae9e7bd8-57d5-43fa-9562-90083b0d0964\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"271a3c02-9739-4a30-9376-6eb5d126d657\",\"type\":\"BasicTicker\"}},\"id\":\"87c81e3b-2b2a-4196-a608-f1b90b32b3f5\",\"type\":\"Grid\"},{\"attributes\":{\"label\":{\"value\":\"Lasso + MLP\"},\"renderers\":[{\"id\":\"23e2ae0c-d7bc-4cec-b9ab-b6ddaf64e872\",\"type\":\"GlyphRenderer\"},{\"id\":\"5bc94e25-45f5-4d08-8d8b-641f7c59b025\",\"type\":\"GlyphRenderer\"}]},\"id\":\"3f7fd5f9-a4d3-4482-a0eb-fa451eaaafcc\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"64619bee-2e0b-4396-acca-8bcf5d73bcbe\",\"type\":\"Circle\"},{\"attributes\":{\"source\":{\"id\":\"e9eb1d57-57b4-4455-9c03-ae0dc59cb1d2\",\"type\":\"ColumnDataSource\"}},\"id\":\"32eb7c49-f556-4397-989e-1dbbaeac7143\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"6cb86b35-17c8-47e4-8647-280b36f4b400\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"729d109c-be65-4384-b1a8-d88f8746be58\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"6d9ea654-5411-4a1d-bf86-fb6719867e61\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"ffa11aac-ea61-4313-a2c8-9531a26196f2\",\"type\":\"CDSView\"}},\"id\":\"00a75378-3647-4f32-b87d-ec237669436d\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"label\":{\"value\":\"DFS\"},\"renderers\":[{\"id\":\"69e8142c-9da0-4832-9ff0-649c701d16cf\",\"type\":\"GlyphRenderer\"},{\"id\":\"10ffeef8-f1e3-47d1-9dae-87a14ee27337\",\"type\":\"GlyphRenderer\"}]},\"id\":\"d8fe8de3-153c-423e-bb2c-482ac9ebb71b\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"f44e752d-6cfd-4b39-9ff4-d8217fb9c414\",\"type\":\"ColumnDataSource\"}},\"id\":\"1f4fdab6-d822-43e3-a8b3-7a1ca13f698c\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"4b842f65-6f1d-4213-b338-4f5462b35332\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"bb176afd-6114-4f2b-9262-7baef3a7cff0\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"9b65a743-bd71-42cb-988e-b3bb2cc79e1b\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"05f4a4cf-cbcc-46cb-9ea3-72cebf9b370d\",\"type\":\"CDSView\"}},\"id\":\"25b7eab9-af52-4977-8225-bea40ede28a2\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a6ac5ea1-4313-4e35-807f-3de2318bb7da\",\"type\":\"BasicTicker\"}},\"id\":\"4a9e9516-797e-431e-b888-7413fc3ed1f6\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"6cb86b35-17c8-47e4-8647-280b36f4b400\",\"type\":\"ColumnDataSource\"}},\"id\":\"ffa11aac-ea61-4313-a2c8-9531a26196f2\",\"type\":\"CDSView\"},{\"attributes\":{\"source\":{\"id\":\"76bd7944-453c-496e-9bcb-27c6ffe48ad6\",\"type\":\"ColumnDataSource\"}},\"id\":\"30c06095-ee8b-480d-846a-bfb61445ff8a\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"f44e752d-6cfd-4b39-9ff4-d8217fb9c414\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"f932741e-a4a0-4685-8883-e59f29bd1b91\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"77e01137-94dc-4d3c-b4f7-1142eb8e9702\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"1f4fdab6-d822-43e3-a8b3-7a1ca13f698c\",\"type\":\"CDSView\"}},\"id\":\"05acaccb-2c05-4aca-a5b5-cad54bbe960b\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ee68f141-e453-41c8-8af3-658d2157d7dd\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"6d9ea654-5411-4a1d-bf86-fb6719867e61\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"DFS + RF\"},\"renderers\":[{\"id\":\"b1e8f8cb-94df-44eb-884e-e81bfcf6296e\",\"type\":\"GlyphRenderer\"},{\"id\":\"887899f0-ea14-40fb-8657-3b876911f8ee\",\"type\":\"GlyphRenderer\"}]},\"id\":\"ef3adefc-2874-4745-9990-d21f7b6196c9\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"9138b5ef-8f93-422c-b773-49cb0b6b94e8\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"07df2f47-fa2a-4ad2-9b98-ebd848fe646c\",\"type\":\"ColumnDataSource\"}},\"id\":\"840ea320-bb25-4390-8bb7-e2a404fa1705\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_color\":{\"value\":\"orange\"},\"line_color\":{\"value\":\"orange\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ca4aa81b-73d0-4d3b-b6d5-9122d4d2bf37\",\"type\":\"Circle\"},{\"attributes\":{\"line_color\":\"cyan\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"757e86ff-2653-4a77-a0ee-ce726230daf0\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8506787330316742,0.8642533936651584,0.8751131221719457,0.869683257918552,0.8877828054298642,0.8760180995475113,0.8687782805429864,0.8778280542986425,0.8742081447963801,0.8787330316742081,0.8714932126696833,0.8669683257918552,0.8760180995475113]}},\"id\":\"4b842f65-6f1d-4213-b338-4f5462b35332\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"label\":{\"value\":\"Lasso + RF\"},\"renderers\":[{\"id\":\"679d46fb-191c-4b77-96da-e44fe6d23fc4\",\"type\":\"GlyphRenderer\"},{\"id\":\"05acaccb-2c05-4aca-a5b5-cad54bbe960b\",\"type\":\"GlyphRenderer\"}]},\"id\":\"e814fc66-1b58-434e-9982-8a9ec2c9d04a\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"cbdd194b-2649-49ce-89b0-9160c2e48f0d\",\"type\":\"Circle\"},{\"attributes\":{\"label\":{\"value\":\"Lasso\"},\"renderers\":[{\"id\":\"ae9e7bd8-57d5-43fa-9562-90083b0d0964\",\"type\":\"GlyphRenderer\"},{\"id\":\"58d2d5b8-97a6-4d31-952c-218b115e3c59\",\"type\":\"GlyphRenderer\"}]},\"id\":\"31c9bc27-606c-4c73-ade0-9ad85b66e1a1\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ea3d55dd-0eac-4f6e-8e06-6eef74647027\",\"type\":\"Circle\"},{\"attributes\":{\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"blue\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d89b4a83-489f-4eae-8f3b-7d4307172ddf\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8461538461538461,0.8461538461538461,0.8461538461538461,0.8470588235294118,0.8470588235294118,0.8461538461538461,0.8461538461538461,0.8470588235294118,0.8470588235294118,0.8470588235294118,0.8461538461538461,0.8470588235294118,0.8470588235294118]}},\"id\":\"e9eb1d57-57b4-4455-9c03-ae0dc59cb1d2\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_color\":{\"value\":\"greenyellow\"},\"line_color\":{\"value\":\"greenyellow\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"f180b434-6d93-417e-8148-6f1d8c2c6193\",\"type\":\"Circle\"},{\"attributes\":{\"fill_color\":{\"value\":\"cyan\"},\"line_color\":{\"value\":\"cyan\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"eb7c37f5-1ef5-421c-a554-a746c79db393\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"a6ac5ea1-4313-4e35-807f-3de2318bb7da\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"3a517dc5-f548-4033-963a-4c8c295b614c\",\"type\":\"Circle\"},{\"attributes\":{\"line_color\":\"orange\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"beaa5734-056f-435d-a9bd-bd4d069e46cf\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"DFS + GB\"},\"renderers\":[{\"id\":\"d3cabbc5-56f2-4cbe-abf9-c657d52c0010\",\"type\":\"GlyphRenderer\"},{\"id\":\"25b7eab9-af52-4977-8225-bea40ede28a2\",\"type\":\"GlyphRenderer\"}]},\"id\":\"c4d8431c-3ce4-486d-a116-7d8f4807340d\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"40480718-c4bc-4005-99e8-522780716da9\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"11271fa5-9622-4991-b53f-4f8571864493\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6bca5fc8-8ef4-460a-9ca1-301ff1031522\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"9138b5ef-8f93-422c-b773-49cb0b6b94e8\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"57f47ba8-ae50-48b6-93e8-e41c0936cd43\",\"type\":\"CDSView\"}},\"id\":\"b1e8f8cb-94df-44eb-884e-e81bfcf6296e\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6ed7d124-bd5e-4447-ae97-f3901b640523\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"e084428b-a14b-4aae-b91b-c43bff28f59e\",\"type\":\"ResetTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"41bab839-1473-4d2b-ab93-2d5bab270f55\",\"type\":\"Line\"},{\"attributes\":{\"below\":[{\"id\":\"95b1f671-4b09-410f-834e-b1315359c43b\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"38ed5cca-da7d-4815-990d-0aef52f59193\",\"type\":\"LinearAxis\"}],\"plot_width\":1000,\"renderers\":[{\"id\":\"95b1f671-4b09-410f-834e-b1315359c43b\",\"type\":\"LinearAxis\"},{\"id\":\"87c81e3b-2b2a-4196-a608-f1b90b32b3f5\",\"type\":\"Grid\"},{\"id\":\"38ed5cca-da7d-4815-990d-0aef52f59193\",\"type\":\"LinearAxis\"},{\"id\":\"4a9e9516-797e-431e-b888-7413fc3ed1f6\",\"type\":\"Grid\"},{\"id\":\"7c0b2d96-2ccc-47d3-b8fd-23ff0bf115a0\",\"type\":\"BoxAnnotation\"},{\"id\":\"26149ed5-3cac-436e-bce4-9e6e5f3f3d5a\",\"type\":\"Legend\"},{\"id\":\"b1e8f8cb-94df-44eb-884e-e81bfcf6296e\",\"type\":\"GlyphRenderer\"},{\"id\":\"887899f0-ea14-40fb-8657-3b876911f8ee\",\"type\":\"GlyphRenderer\"},{\"id\":\"d3cabbc5-56f2-4cbe-abf9-c657d52c0010\",\"type\":\"GlyphRenderer\"},{\"id\":\"25b7eab9-af52-4977-8225-bea40ede28a2\",\"type\":\"GlyphRenderer\"},{\"id\":\"679d46fb-191c-4b77-96da-e44fe6d23fc4\",\"type\":\"GlyphRenderer\"},{\"id\":\"05acaccb-2c05-4aca-a5b5-cad54bbe960b\",\"type\":\"GlyphRenderer\"},{\"id\":\"00a75378-3647-4f32-b87d-ec237669436d\",\"type\":\"GlyphRenderer\"},{\"id\":\"0c2f7411-7fcc-4ab2-8249-835269a06840\",\"type\":\"GlyphRenderer\"},{\"id\":\"69e8142c-9da0-4832-9ff0-649c701d16cf\",\"type\":\"GlyphRenderer\"},{\"id\":\"10ffeef8-f1e3-47d1-9dae-87a14ee27337\",\"type\":\"GlyphRenderer\"},{\"id\":\"ae9e7bd8-57d5-43fa-9562-90083b0d0964\",\"type\":\"GlyphRenderer\"},{\"id\":\"58d2d5b8-97a6-4d31-952c-218b115e3c59\",\"type\":\"GlyphRenderer\"},{\"id\":\"bbad7a9a-d59e-4f00-95a2-d6c5a9b6ed27\",\"type\":\"GlyphRenderer\"},{\"id\":\"27dd07fe-f4f7-44f0-994a-c76ab55a9dd6\",\"type\":\"GlyphRenderer\"},{\"id\":\"23e2ae0c-d7bc-4cec-b9ab-b6ddaf64e872\",\"type\":\"GlyphRenderer\"},{\"id\":\"5bc94e25-45f5-4d08-8d8b-641f7c59b025\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"a435f710-23ef-4edb-9217-f1e6acb0ebf1\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"bafbfa38-016f-4775-ae24-fce9c7fe71c0\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"209bebc5-f43f-4b5e-a8f4-ee25a61772ff\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"aaf27988-bc94-4b8c-838f-e0505b371f7e\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"143c1667-042f-4bde-abaf-54062fd2638d\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"e9998a99-25ed-4504-87a1-bb653ffadbfd\",\"type\":\"LinearScale\"}},\"id\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"331ecd5d-e229-4172-a498-7cbfb795be0b\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8479638009049774,0.8552036199095022,0.8597285067873304,0.8615384615384616,0.8760180995475113,0.8515837104072398,0.8552036199095022,0.8570135746606334,0.860633484162896,0.8687782805429864,0.848868778280543,0.8461538461538461,0.8542986425339366]}},\"id\":\"d3462164-b928-442b-9e8f-5e18696be405\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"ef17ae49-b17f-4284-ac4c-df9bd76b5a38\",\"type\":\"ColumnDataSource\"}},\"id\":\"43b623df-2f68-477c-a37e-a993b0940877\",\"type\":\"CDSView\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"a435f710-23ef-4edb-9217-f1e6acb0ebf1\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"d3462164-b928-442b-9e8f-5e18696be405\",\"type\":\"ColumnDataSource\"}},\"id\":\"7abaac03-e7dd-4251-9ea8-4aa518f5e65d\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8633484162895928,0.8705882352941177,0.8705882352941177,0.8787330316742081,0.8796380090497737,0.8778280542986425,0.8823529411764706,0.8796380090497737,0.8805429864253393,0.8787330316742081,0.8832579185520362,0.881447963800905,0.8751131221719457]}},\"id\":\"539a4421-ffa1-48cc-b338-b93669ba479c\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"539a4421-ffa1-48cc-b338-b93669ba479c\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"82f99764-5a28-4080-a648-279eb25a5b74\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"3a517dc5-f548-4033-963a-4c8c295b614c\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"4eee1c21-12f3-4fb3-87df-0eca7b5564c5\",\"type\":\"CDSView\"}},\"id\":\"0c2f7411-7fcc-4ab2-8249-835269a06840\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"77e01137-94dc-4d3c-b4f7-1142eb8e9702\",\"type\":\"Circle\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"031fa2c8-cacc-4039-a7a9-215aeadfc4a8\",\"type\":\"Circle\"},{\"attributes\":{\"source\":{\"id\":\"3dcd023e-f25a-49ea-9889-4fa85f8bd4ae\",\"type\":\"ColumnDataSource\"}},\"id\":\"007f9062-7908-4b31-83e6-4f4baa279336\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[10,50,100,150,200,250,300,350,400,500,750,1000,1524],\"y\":[0.8561085972850678,0.8561085972850678,0.853393665158371,0.8506787330316742,0.8561085972850678,0.8561085972850678,0.8497737556561086,0.860633484162896,0.8588235294117647,0.8506787330316742,0.8515837104072398,0.8570135746606334,0.8352941176470589]}},\"id\":\"c1d0cc60-36eb-4e2b-95b6-9225b1ede669\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null},\"id\":\"209bebc5-f43f-4b5e-a8f4-ee25a61772ff\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"11271fa5-9622-4991-b53f-4f8571864493\",\"type\":\"ColumnDataSource\"}},\"id\":\"57f47ba8-ae50-48b6-93e8-e41c0936cd43\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"brown\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1995c00e-4fa7-4852-95a3-22109482f1bf\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"e9998a99-25ed-4504-87a1-bb653ffadbfd\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"62c5e922-0586-4db9-b057-baf8b88dc94b\",\"type\":\"ColumnDataSource\"}},\"id\":\"f5456d1b-14d4-43ac-8509-132683c243c7\",\"type\":\"CDSView\"}],\"root_ids\":[\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"f01e372e-5e27-4b54-9193-21b12a40cd71\",\"elementid\":\"0cef2233-c428-4bc2-82e8-ea5c952f9e1a\",\"modelid\":\"6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "6b5ad4f5-1790-4c66-b9a0-b27fa1ca98ed"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "0px",
    "width": "250px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1182px",
    "left": "0px",
    "right": "1792.4815673828125px",
    "top": "52.22426223754883px",
    "width": "184px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
